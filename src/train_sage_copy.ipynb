{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10963204-8965-4b82-b5ec-e1e50d44c89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from models_sage import HeteroGraphSAGE\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df6a337-a422-47d3-b84f-208b1885e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility control\n",
    "import torch, random, numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d574e7bc-6b3f-4fad-83c9-e94333b30ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [42, 43, 44, 45, 46]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69c6622-d93b-4da7-affb-453503426af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: C:\\Users\\ayish\\OneDrive\\Documents\\circRNA-disease-gnn\n",
      "DATA_DIR: C:\\Users\\ayish\\OneDrive\\Documents\\circRNA-disease-gnn\\data\\data_cleaned\n",
      "GRAPH_PATH: C:\\Users\\ayish\\OneDrive\\Documents\\circRNA-disease-gnn\\outputs\\data.pt\n"
     ]
    }
   ],
   "source": [
    "# Notebook-safe paths\n",
    "ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = ROOT / \"data\" / \"data_cleaned\"\n",
    "GRAPH_PATH = ROOT / \"outputs\" / \"data.pt\"\n",
    "OUT_DIR = ROOT / \"outputs\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"GRAPH_PATH:\", GRAPH_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b5ab0-bd3f-45cf-ad8f-72ec2b53dfaf",
   "metadata": {},
   "source": [
    "### Load node preserving labelled splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c57f55f-acaf-4b85-99a5-87480c25a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(name, le_circ, le_dis):\n",
    "    df = pd.read_csv(DATA_DIR / name)\n",
    "\n",
    "    # Encode node names → integer IDs\n",
    "    circ_ids = le_circ.transform(df[\"circRNA\"].astype(str))\n",
    "    dis_ids  = le_dis.transform(df[\"disease\"].astype(str))\n",
    "\n",
    "    # Build edge index: [2, num_edges]\n",
    "    edges = torch.from_numpy(np.vstack([circ_ids, dis_ids])).long()\n",
    "\n",
    "    # Labels (already numeric)\n",
    "    labels = torch.tensor(df[\"label\"].values, dtype=torch.float)\n",
    "\n",
    "    return edges, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566f900b-ca8c-4bc0-9b17-d047e813b678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 929]), torch.Size([929]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders = torch.load(\n",
    "    OUT_DIR / \"label_encoders.pt\",\n",
    "    weights_only=False\n",
    ")\n",
    "\n",
    "le_circ = encoders[\"circRNA\"]\n",
    "le_dis  = encoders[\"disease\"]\n",
    "\n",
    "\n",
    "train_edges, train_labels = load_split(\"circRNA_disease_train.csv\", le_circ, le_dis)\n",
    "val_edges, val_labels     = load_split(\"circRNA_disease_val.csv\", le_circ, le_dis)\n",
    "test_edges, test_labels   = load_split(\"circRNA_disease_test.csv\", le_circ, le_dis)\n",
    "\n",
    "train_edges.shape, train_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704f446a-6752-4148-b083-8ac395de1b95",
   "metadata": {},
   "source": [
    "### Move Splits to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce7939b-123d-4efb-b5ae-2883f5a0ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges, train_labels = train_edges.to(DEVICE), train_labels.to(DEVICE)\n",
    "val_edges, val_labels     = val_edges.to(DEVICE), val_labels.to(DEVICE)\n",
    "test_edges, test_labels   = test_edges.to(DEVICE), test_labels.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8076ca-c6d9-4793-90d3-c69d2859177e",
   "metadata": {},
   "source": [
    "### Load HeteroGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9fb258-75cd-49ff-ae11-e556d2794321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading heterogeneous graph...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  circRNA={ x=[828, 6] },\n",
       "  miRNA={ x=[521, 6] },\n",
       "  disease={ x=[122, 6] },\n",
       "  (circRNA, interacts, miRNA)={ edge_index=[2, 896] },\n",
       "  (miRNA, interacts, disease)={ edge_index=[2, 828] },\n",
       "  (circRNA, associated, disease)={ edge_index=[2, 985] },\n",
       "  (circRNA, gip_sim, circRNA)={\n",
       "    edge_index=[2, 685584],\n",
       "    edge_weight=[685584],\n",
       "  },\n",
       "  (miRNA, gip_sim, miRNA)={\n",
       "    edge_index=[2, 271441],\n",
       "    edge_weight=[271441],\n",
       "  },\n",
       "  (miRNA, rev_interacts, circRNA)={ edge_index=[2, 896] },\n",
       "  (disease, rev_interacts, miRNA)={ edge_index=[2, 828] },\n",
       "  (disease, rev_associated, circRNA)={ edge_index=[2, 985] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading heterogeneous graph...\")\n",
    "data = torch.load(\n",
    "    GRAPH_PATH,\n",
    "    map_location=DEVICE,\n",
    "    weights_only=False\n",
    ")\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f819c8-1d8e-4c2a-b6f3-627a87b1417e",
   "metadata": {},
   "source": [
    "### Initialize GraphSAGE model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5392db27-3cd4-42cc-b63c-c56760244b12",
   "metadata": {},
   "source": [
    "model = HeteroGraphSAGE(\n",
    "    in_channels=data[\"circRNA\"].x.size(1),\n",
    "    hidden_channels=64,\n",
    "    out_channels=64,\n",
    "    dropout=0.2\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "893844b8-b290-48f6-9400-131a3e982022",
   "metadata": {},
   "source": [
    "best_val_aupr = 0.0\n",
    "\n",
    "print(\"\\nStarting GraphSAGE training...\\n\")\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    # -------- Training --------\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    emb = model(data.x_dict, data.edge_index_dict)\n",
    "    circ_emb, dis_emb = emb[\"circRNA\"], emb[\"disease\"]\n",
    "\n",
    "    logits = (circ_emb[train_edges[0]] * dis_emb[train_edges[1]]).sum(dim=1)\n",
    "    loss = loss_fn(logits, train_labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # -------- Validation --------\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        emb = model(data.x_dict, data.edge_index_dict)\n",
    "        circ_emb, dis_emb = emb[\"circRNA\"], emb[\"disease\"]\n",
    "\n",
    "        val_logits = (circ_emb[val_edges[0]] * dis_emb[val_edges[1]]).sum(dim=1)\n",
    "        val_scores = torch.sigmoid(val_logits).cpu().numpy()\n",
    "        val_true   = val_labels.cpu().numpy()\n",
    "\n",
    "        auc = roc_auc_score(val_true, val_scores)\n",
    "        aupr = average_precision_score(val_true, val_scores)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"Loss {loss.item():.4f} | \"\n",
    "        f\"Val AUC {auc:.4f} | \"\n",
    "        f\"Val AUPR {aupr:.4f}\"\n",
    "    )\n",
    "\n",
    "    if aupr > best_val_aupr:\n",
    "        best_val_aupr = aupr\n",
    "        torch.save(model.state_dict(), OUT_DIR / \"sage_best_model.pth\")\n",
    "        print(\"   → Saved best model\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6eda3631-d828-4dbc-8343-6dbcea70f6db",
   "metadata": {},
   "source": [
    "print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "model.load_state_dict(torch.load(OUT_DIR / \"sage_best_model.pth\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb = model(data.x_dict, data.edge_index_dict)\n",
    "    circ_emb, dis_emb = emb[\"circRNA\"], emb[\"disease\"]\n",
    "\n",
    "    test_logits = (circ_emb[test_edges[0]] * dis_emb[test_edges[1]]).sum(dim=1)\n",
    "    test_scores = torch.sigmoid(test_logits).cpu().numpy()\n",
    "    test_true   = test_labels.cpu().numpy()\n",
    "\n",
    "    test_auc = roc_auc_score(test_true, test_scores)\n",
    "    test_aupr = average_precision_score(test_true, test_scores)\n",
    "\n",
    "print(\"\\nFINAL TEST RESULTS\")\n",
    "print(f\"AUC  = {test_auc:.4f}\")\n",
    "print(f\"AUPR = {test_aupr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c148e4f1-a496-48d1-8fd6-5cb31a686e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim * 3, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, z_c, z_d):\n",
    "        x = torch.cat([z_c, z_d, z_c * z_d], dim=1)\n",
    "        return self.mlp(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a292c6e5-0941-4eb7-be64-8273f63e1b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Running experiment with SEED = 42\n",
      "==============================\n",
      "3Layer\n",
      "mlp.0.weight 0.1529686003923416\n",
      "mlp.0.bias 0.135014146566391\n",
      "mlp.2.weight 0.15002262592315674\n",
      "mlp.2.bias 0.4126432240009308\n",
      "3Layer\n",
      "Epoch 001 | Loss 0.6654 | Val AUC 0.8741 | Val AUPR 0.4865\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.13129237294197083\n",
      "mlp.0.bias 0.11336798965930939\n",
      "mlp.2.weight 0.15494771301746368\n",
      "mlp.2.bias 0.39927923679351807\n",
      "3Layer\n",
      "Epoch 002 | Loss 0.6433 | Val AUC 0.8798 | Val AUPR 0.4997\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.12306120246648788\n",
      "mlp.0.bias 0.1040099561214447\n",
      "mlp.2.weight 0.1810811311006546\n",
      "mlp.2.bias 0.3890114426612854\n",
      "3Layer\n",
      "Epoch 003 | Loss 0.6268 | Val AUC 0.8869 | Val AUPR 0.6146\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.12400288134813309\n",
      "mlp.0.bias 0.10271754115819931\n",
      "mlp.2.weight 0.20682412385940552\n",
      "mlp.2.bias 0.3810746669769287\n",
      "3Layer\n",
      "Epoch 004 | Loss 0.6144 | Val AUC 0.8947 | Val AUPR 0.6526\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.13091687858104706\n",
      "mlp.0.bias 0.10637342929840088\n",
      "mlp.2.weight 0.23666547238826752\n",
      "mlp.2.bias 0.3728770911693573\n",
      "3Layer\n",
      "Epoch 005 | Loss 0.6019 | Val AUC 0.8988 | Val AUPR 0.6619\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.13530850410461426\n",
      "mlp.0.bias 0.1073770523071289\n",
      "mlp.2.weight 0.26192325353622437\n",
      "mlp.2.bias 0.3653663694858551\n",
      "3Layer\n",
      "Epoch 006 | Loss 0.5907 | Val AUC 0.8977 | Val AUPR 0.6049\n",
      "3Layer\n",
      "mlp.0.weight 0.13680605590343475\n",
      "mlp.0.bias 0.107612743973732\n",
      "mlp.2.weight 0.2827624976634979\n",
      "mlp.2.bias 0.35847121477127075\n",
      "3Layer\n",
      "Epoch 007 | Loss 0.5806 | Val AUC 0.8872 | Val AUPR 0.5190\n",
      "3Layer\n",
      "mlp.0.weight 0.1400962918996811\n",
      "mlp.0.bias 0.10822927206754684\n",
      "mlp.2.weight 0.3053610324859619\n",
      "mlp.2.bias 0.3512018918991089\n",
      "3Layer\n",
      "Epoch 008 | Loss 0.5700 | Val AUC 0.8777 | Val AUPR 0.4821\n",
      "3Layer\n",
      "mlp.0.weight 0.14125096797943115\n",
      "mlp.0.bias 0.10863858461380005\n",
      "mlp.2.weight 0.32339125871658325\n",
      "mlp.2.bias 0.3442768454551697\n",
      "3Layer\n",
      "Epoch 009 | Loss 0.5604 | Val AUC 0.8725 | Val AUPR 0.4157\n",
      "3Layer\n",
      "mlp.0.weight 0.14759530127048492\n",
      "mlp.0.bias 0.11178954690694809\n",
      "mlp.2.weight 0.34325188398361206\n",
      "mlp.2.bias 0.3363848030567169\n",
      "3Layer\n",
      "Epoch 010 | Loss 0.5492 | Val AUC 0.8649 | Val AUPR 0.3768\n",
      "3Layer\n",
      "mlp.0.weight 0.1485053449869156\n",
      "mlp.0.bias 0.11179912835359573\n",
      "mlp.2.weight 0.3595537841320038\n",
      "mlp.2.bias 0.3293509781360626\n",
      "3Layer\n",
      "Epoch 011 | Loss 0.5395 | Val AUC 0.8581 | Val AUPR 0.3543\n",
      "3Layer\n",
      "mlp.0.weight 0.14864066243171692\n",
      "mlp.0.bias 0.11060801893472672\n",
      "mlp.2.weight 0.37656140327453613\n",
      "mlp.2.bias 0.3215107321739197\n",
      "3Layer\n",
      "Epoch 012 | Loss 0.5290 | Val AUC 0.8535 | Val AUPR 0.3421\n",
      "3Layer\n",
      "mlp.0.weight 0.14741148054599762\n",
      "mlp.0.bias 0.10941266268491745\n",
      "mlp.2.weight 0.3901311159133911\n",
      "mlp.2.bias 0.31419089436531067\n",
      "3Layer\n",
      "Epoch 013 | Loss 0.5191 | Val AUC 0.8498 | Val AUPR 0.3378\n",
      "3Layer\n",
      "mlp.0.weight 0.14660397171974182\n",
      "mlp.0.bias 0.10802826285362244\n",
      "mlp.2.weight 0.40461936593055725\n",
      "mlp.2.bias 0.3064415156841278\n",
      "3Layer\n",
      "Epoch 014 | Loss 0.5089 | Val AUC 0.8510 | Val AUPR 0.3419\n",
      "3Layer\n",
      "mlp.0.weight 0.1453874409198761\n",
      "mlp.0.bias 0.10671693086624146\n",
      "mlp.2.weight 0.416242390871048\n",
      "mlp.2.bias 0.2990380823612213\n",
      "3Layer\n",
      "Epoch 015 | Loss 0.4993 | Val AUC 0.8566 | Val AUPR 0.3600\n",
      "3Layer\n",
      "mlp.0.weight 0.14363917708396912\n",
      "mlp.0.bias 0.10531686991453171\n",
      "mlp.2.weight 0.42752617597579956\n",
      "mlp.2.bias 0.29146134853363037\n",
      "3Layer\n",
      "Epoch 016 | Loss 0.4897 | Val AUC 0.8627 | Val AUPR 0.3836\n",
      "3Layer\n",
      "mlp.0.weight 0.1422117054462433\n",
      "mlp.0.bias 0.10368946194648743\n",
      "mlp.2.weight 0.4385537803173065\n",
      "mlp.2.bias 0.2834375202655792\n",
      "3Layer\n",
      "Epoch 017 | Loss 0.4796 | Val AUC 0.8721 | Val AUPR 0.4157\n",
      "3Layer\n",
      "mlp.0.weight 0.14025256037712097\n",
      "mlp.0.bias 0.10204285383224487\n",
      "mlp.2.weight 0.44776731729507446\n",
      "mlp.2.bias 0.2754674255847931\n",
      "3Layer\n",
      "Epoch 018 | Loss 0.4699 | Val AUC 0.8824 | Val AUPR 0.4531\n",
      "3Layer\n",
      "mlp.0.weight 0.13813121616840363\n",
      "mlp.0.bias 0.10018876940011978\n",
      "mlp.2.weight 0.45653852820396423\n",
      "mlp.2.bias 0.2670321762561798\n",
      "3Layer\n",
      "Epoch 019 | Loss 0.4599 | Val AUC 0.8857 | Val AUPR 0.4638\n",
      "3Layer\n",
      "mlp.0.weight 0.13617171347141266\n",
      "mlp.0.bias 0.09854481369256973\n",
      "mlp.2.weight 0.46296486258506775\n",
      "mlp.2.bias 0.2586269676685333\n",
      "3Layer\n",
      "Epoch 020 | Loss 0.4499 | Val AUC 0.8915 | Val AUPR 0.5008\n",
      "3Layer\n",
      "mlp.0.weight 0.1337835192680359\n",
      "mlp.0.bias 0.09668536484241486\n",
      "mlp.2.weight 0.4691917598247528\n",
      "mlp.2.bias 0.24996371567249298\n",
      "3Layer\n",
      "Epoch 021 | Loss 0.4398 | Val AUC 0.8962 | Val AUPR 0.5245\n",
      "3Layer\n",
      "mlp.0.weight 0.1316070705652237\n",
      "mlp.0.bias 0.09482195228338242\n",
      "mlp.2.weight 0.4728623926639557\n",
      "mlp.2.bias 0.24122354388237\n",
      "3Layer\n",
      "Epoch 022 | Loss 0.4299 | Val AUC 0.9005 | Val AUPR 0.5494\n",
      "3Layer\n",
      "mlp.0.weight 0.12867261469364166\n",
      "mlp.0.bias 0.09259594231843948\n",
      "mlp.2.weight 0.47458145022392273\n",
      "mlp.2.bias 0.23227812349796295\n",
      "3Layer\n",
      "Epoch 023 | Loss 0.4201 | Val AUC 0.9042 | Val AUPR 0.5743\n",
      "3Layer\n",
      "mlp.0.weight 0.12538866698741913\n",
      "mlp.0.bias 0.09022581577301025\n",
      "mlp.2.weight 0.475921094417572\n",
      "mlp.2.bias 0.22353321313858032\n",
      "3Layer\n",
      "Epoch 024 | Loss 0.4104 | Val AUC 0.9063 | Val AUPR 0.6077\n",
      "3Layer\n",
      "mlp.0.weight 0.1219869926571846\n",
      "mlp.0.bias 0.08757365494966507\n",
      "mlp.2.weight 0.4751564860343933\n",
      "mlp.2.bias 0.21430127322673798\n",
      "3Layer\n",
      "Epoch 025 | Loss 0.4006 | Val AUC 0.9081 | Val AUPR 0.6395\n",
      "3Layer\n",
      "mlp.0.weight 0.11841366440057755\n",
      "mlp.0.bias 0.08486463129520416\n",
      "mlp.2.weight 0.47234463691711426\n",
      "mlp.2.bias 0.20513594150543213\n",
      "3Layer\n",
      "Epoch 026 | Loss 0.3912 | Val AUC 0.9081 | Val AUPR 0.6575\n",
      "3Layer\n",
      "mlp.0.weight 0.11468534171581268\n",
      "mlp.0.bias 0.08225910365581512\n",
      "mlp.2.weight 0.4682013690471649\n",
      "mlp.2.bias 0.1964237242937088\n",
      "3Layer\n",
      "Epoch 027 | Loss 0.3823 | Val AUC 0.9080 | Val AUPR 0.6691\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.11082644015550613\n",
      "mlp.0.bias 0.0793130174279213\n",
      "mlp.2.weight 0.46276718378067017\n",
      "mlp.2.bias 0.18710550665855408\n",
      "3Layer\n",
      "Epoch 028 | Loss 0.3731 | Val AUC 0.9082 | Val AUPR 0.6743\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.10684913396835327\n",
      "mlp.0.bias 0.07645346224308014\n",
      "mlp.2.weight 0.45564350485801697\n",
      "mlp.2.bias 0.17820283770561218\n",
      "3Layer\n",
      "Epoch 029 | Loss 0.3645 | Val AUC 0.9078 | Val AUPR 0.6752\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.10280255973339081\n",
      "mlp.0.bias 0.07349759340286255\n",
      "mlp.2.weight 0.44752925634384155\n",
      "mlp.2.bias 0.16928376257419586\n",
      "3Layer\n",
      "Epoch 030 | Loss 0.3562 | Val AUC 0.9072 | Val AUPR 0.6733\n",
      "3Layer\n",
      "mlp.0.weight 0.0986952930688858\n",
      "mlp.0.bias 0.07045704871416092\n",
      "mlp.2.weight 0.43776246905326843\n",
      "mlp.2.bias 0.16037876904010773\n",
      "3Layer\n",
      "Epoch 031 | Loss 0.3480 | Val AUC 0.9068 | Val AUPR 0.6666\n",
      "3Layer\n",
      "mlp.0.weight 0.0944012925028801\n",
      "mlp.0.bias 0.06739076972007751\n",
      "mlp.2.weight 0.42694148421287537\n",
      "mlp.2.bias 0.15162283182144165\n",
      "3Layer\n",
      "Epoch 032 | Loss 0.3403 | Val AUC 0.9056 | Val AUPR 0.6608\n",
      "3Layer\n",
      "mlp.0.weight 0.09021515399217606\n",
      "mlp.0.bias 0.0643155500292778\n",
      "mlp.2.weight 0.4152820110321045\n",
      "mlp.2.bias 0.14305055141448975\n",
      "3Layer\n",
      "Epoch 033 | Loss 0.3327 | Val AUC 0.9049 | Val AUPR 0.6533\n",
      "3Layer\n",
      "mlp.0.weight 0.08582579344511032\n",
      "mlp.0.bias 0.06110829859972\n",
      "mlp.2.weight 0.4017673134803772\n",
      "mlp.2.bias 0.13438674807548523\n",
      "3Layer\n",
      "Epoch 034 | Loss 0.3255 | Val AUC 0.9037 | Val AUPR 0.6472\n",
      "3Layer\n",
      "mlp.0.weight 0.08152898401021957\n",
      "mlp.0.bias 0.05798855796456337\n",
      "mlp.2.weight 0.38756218552589417\n",
      "mlp.2.bias 0.12611320614814758\n",
      "3Layer\n",
      "Epoch 035 | Loss 0.3188 | Val AUC 0.9030 | Val AUPR 0.6440\n",
      "3Layer\n",
      "mlp.0.weight 0.07725641876459122\n",
      "mlp.0.bias 0.054995954036712646\n",
      "mlp.2.weight 0.3729597330093384\n",
      "mlp.2.bias 0.11830306053161621\n",
      "3Layer\n",
      "Epoch 036 | Loss 0.3127 | Val AUC 0.9022 | Val AUPR 0.6406\n",
      "3Layer\n",
      "mlp.0.weight 0.07289110124111176\n",
      "mlp.0.bias 0.051855865865945816\n",
      "mlp.2.weight 0.3571423888206482\n",
      "mlp.2.bias 0.11035718023777008\n",
      "3Layer\n",
      "Epoch 037 | Loss 0.3067 | Val AUC 0.9021 | Val AUPR 0.6374\n",
      "3Layer\n",
      "mlp.0.weight 0.06871659308671951\n",
      "mlp.0.bias 0.04888296499848366\n",
      "mlp.2.weight 0.3411481976509094\n",
      "mlp.2.bias 0.1029423326253891\n",
      "3Layer\n",
      "Epoch 038 | Loss 0.3013 | Val AUC 0.9018 | Val AUPR 0.6355\n",
      "3Layer\n",
      "mlp.0.weight 0.06440071016550064\n",
      "mlp.0.bias 0.04568934813141823\n",
      "mlp.2.weight 0.32391858100891113\n",
      "mlp.2.bias 0.095232754945755\n",
      "3Layer\n",
      "Epoch 039 | Loss 0.2958 | Val AUC 0.9014 | Val AUPR 0.6310\n",
      "3Layer\n",
      "mlp.0.weight 0.060319773852825165\n",
      "mlp.0.bias 0.042797576636075974\n",
      "mlp.2.weight 0.3070635199546814\n",
      "mlp.2.bias 0.08831453323364258\n",
      "3Layer\n",
      "Epoch 040 | Loss 0.2912 | Val AUC 0.9002 | Val AUPR 0.6239\n",
      "3Layer\n",
      "mlp.0.weight 0.056300390511751175\n",
      "mlp.0.bias 0.0399504192173481\n",
      "mlp.2.weight 0.2900468111038208\n",
      "mlp.2.bias 0.08163706213235855\n",
      "3Layer\n",
      "Epoch 041 | Loss 0.2869 | Val AUC 0.8987 | Val AUPR 0.6125\n",
      "3Layer\n",
      "mlp.0.weight 0.052352774888277054\n",
      "mlp.0.bias 0.037124425172805786\n",
      "mlp.2.weight 0.27269914746284485\n",
      "mlp.2.bias 0.07514410465955734\n",
      "3Layer\n",
      "Epoch 042 | Loss 0.2828 | Val AUC 0.8980 | Val AUPR 0.6090\n",
      "3Layer\n",
      "mlp.0.weight 0.048519495874643326\n",
      "mlp.0.bias 0.03433215245604515\n",
      "mlp.2.weight 0.25539830327033997\n",
      "mlp.2.bias 0.06885342299938202\n",
      "3Layer\n",
      "Epoch 043 | Loss 0.2790 | Val AUC 0.8981 | Val AUPR 0.5927\n",
      "3Layer\n",
      "mlp.0.weight 0.04467156529426575\n",
      "mlp.0.bias 0.03158961609005928\n",
      "mlp.2.weight 0.23755398392677307\n",
      "mlp.2.bias 0.06278882175683975\n",
      "3Layer\n",
      "Epoch 044 | Loss 0.2757 | Val AUC 0.8979 | Val AUPR 0.5904\n",
      "3Layer\n",
      "mlp.0.weight 0.041174035519361496\n",
      "mlp.0.bias 0.029116066172719002\n",
      "mlp.2.weight 0.22094224393367767\n",
      "mlp.2.bias 0.05737367272377014\n",
      "3Layer\n",
      "Epoch 045 | Loss 0.2728 | Val AUC 0.8987 | Val AUPR 0.5920\n",
      "3Layer\n",
      "mlp.0.weight 0.037687480449676514\n",
      "mlp.0.bias 0.026613758876919746\n",
      "mlp.2.weight 0.20385290682315826\n",
      "mlp.2.bias 0.05200672149658203\n",
      "3Layer\n",
      "Epoch 046 | Loss 0.2701 | Val AUC 0.8992 | Val AUPR 0.5955\n",
      "3Layer\n",
      "mlp.0.weight 0.03437308967113495\n",
      "mlp.0.bias 0.024259457364678383\n",
      "mlp.2.weight 0.1876128762960434\n",
      "mlp.2.bias 0.04702641814947128\n",
      "3Layer\n",
      "Epoch 047 | Loss 0.2677 | Val AUC 0.9001 | Val AUPR 0.6013\n",
      "3Layer\n",
      "mlp.0.weight 0.03123369626700878\n",
      "mlp.0.bias 0.02194957807660103\n",
      "mlp.2.weight 0.17170867323875427\n",
      "mlp.2.bias 0.04222126305103302\n",
      "3Layer\n",
      "Epoch 048 | Loss 0.2654 | Val AUC 0.9001 | Val AUPR 0.6058\n",
      "3Layer\n",
      "mlp.0.weight 0.02833099663257599\n",
      "mlp.0.bias 0.019831540063023567\n",
      "mlp.2.weight 0.15686273574829102\n",
      "mlp.2.bias 0.03786555677652359\n",
      "3Layer\n",
      "Epoch 049 | Loss 0.2635 | Val AUC 0.8995 | Val AUPR 0.6103\n",
      "3Layer\n",
      "mlp.0.weight 0.025375382974743843\n",
      "mlp.0.bias 0.017742522060871124\n",
      "mlp.2.weight 0.1414719521999359\n",
      "mlp.2.bias 0.03363765776157379\n",
      "3Layer\n",
      "Epoch 050 | Loss 0.2619 | Val AUC 0.8991 | Val AUPR 0.6079\n",
      "3Layer\n",
      "SEED 42 | Test AUC 0.8989 | Test AUPR 0.5875\n",
      "\n",
      "==============================\n",
      "Running experiment with SEED = 43\n",
      "==============================\n",
      "3Layer\n",
      "mlp.0.weight 0.18399426341056824\n",
      "mlp.0.bias 0.1592615395784378\n",
      "mlp.2.weight 0.16517551243305206\n",
      "mlp.2.bias 0.4480634033679962\n",
      "3Layer\n",
      "Epoch 001 | Loss 0.7271 | Val AUC 0.3507 | Val AUPR 0.0883\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15850447118282318\n",
      "mlp.0.bias 0.13740967214107513\n",
      "mlp.2.weight 0.15922138094902039\n",
      "mlp.2.bias 0.432860791683197\n",
      "3Layer\n",
      "Epoch 002 | Loss 0.6998 | Val AUC 0.4384 | Val AUPR 0.1022\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.14990052580833435\n",
      "mlp.0.bias 0.12606589496135712\n",
      "mlp.2.weight 0.18606504797935486\n",
      "mlp.2.bias 0.42071518301963806\n",
      "3Layer\n",
      "Epoch 003 | Loss 0.6789 | Val AUC 0.5068 | Val AUPR 0.1192\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15133972465991974\n",
      "mlp.0.bias 0.12429288029670715\n",
      "mlp.2.weight 0.21350526809692383\n",
      "mlp.2.bias 0.41157519817352295\n",
      "3Layer\n",
      "Epoch 004 | Loss 0.6636 | Val AUC 0.4955 | Val AUPR 0.1192\n",
      "3Layer\n",
      "mlp.0.weight 0.1542721390724182\n",
      "mlp.0.bias 0.12533561885356903\n",
      "mlp.2.weight 0.23890765011310577\n",
      "mlp.2.bias 0.4034841060638428\n",
      "3Layer\n",
      "Epoch 005 | Loss 0.6503 | Val AUC 0.5326 | Val AUPR 0.1263\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15844054520130157\n",
      "mlp.0.bias 0.12628260254859924\n",
      "mlp.2.weight 0.2659635841846466\n",
      "mlp.2.bias 0.395710289478302\n",
      "3Layer\n",
      "Epoch 006 | Loss 0.6379 | Val AUC 0.5887 | Val AUPR 0.1308\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.16570739448070526\n",
      "mlp.0.bias 0.1294749528169632\n",
      "mlp.2.weight 0.2880770266056061\n",
      "mlp.2.bias 0.3879550099372864\n",
      "3Layer\n",
      "Epoch 007 | Loss 0.6256 | Val AUC 0.7724 | Val AUPR 0.2175\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.17217493057250977\n",
      "mlp.0.bias 0.13351470232009888\n",
      "mlp.2.weight 0.3097011148929596\n",
      "mlp.2.bias 0.37975558638572693\n",
      "3Layer\n",
      "Epoch 008 | Loss 0.6128 | Val AUC 0.8481 | Val AUPR 0.3046\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.17580898106098175\n",
      "mlp.0.bias 0.13431797921657562\n",
      "mlp.2.weight 0.33195436000823975\n",
      "mlp.2.bias 0.37112462520599365\n",
      "3Layer\n",
      "Epoch 009 | Loss 0.5997 | Val AUC 0.8835 | Val AUPR 0.4085\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1756795197725296\n",
      "mlp.0.bias 0.133750319480896\n",
      "mlp.2.weight 0.34904468059539795\n",
      "mlp.2.bias 0.36290833353996277\n",
      "3Layer\n",
      "Epoch 010 | Loss 0.5873 | Val AUC 0.9016 | Val AUPR 0.5426\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.17465424537658691\n",
      "mlp.0.bias 0.1319299340248108\n",
      "mlp.2.weight 0.3669496178627014\n",
      "mlp.2.bias 0.3541682958602905\n",
      "3Layer\n",
      "Epoch 011 | Loss 0.5744 | Val AUC 0.9070 | Val AUPR 0.6156\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.17341120541095734\n",
      "mlp.0.bias 0.1298113316297531\n",
      "mlp.2.weight 0.38530391454696655\n",
      "mlp.2.bias 0.3449752926826477\n",
      "3Layer\n",
      "Epoch 012 | Loss 0.5614 | Val AUC 0.9052 | Val AUPR 0.6136\n",
      "3Layer\n",
      "mlp.0.weight 0.1715131402015686\n",
      "mlp.0.bias 0.12782405316829681\n",
      "mlp.2.weight 0.40067052841186523\n",
      "mlp.2.bias 0.33624550700187683\n",
      "3Layer\n",
      "Epoch 013 | Loss 0.5489 | Val AUC 0.9042 | Val AUPR 0.5908\n",
      "3Layer\n",
      "mlp.0.weight 0.16992758214473724\n",
      "mlp.0.bias 0.12594860792160034\n",
      "mlp.2.weight 0.4152892529964447\n",
      "mlp.2.bias 0.32747724652290344\n",
      "3Layer\n",
      "Epoch 014 | Loss 0.5368 | Val AUC 0.9042 | Val AUPR 0.5889\n",
      "3Layer\n",
      "mlp.0.weight 0.1679879128932953\n",
      "mlp.0.bias 0.12412819266319275\n",
      "mlp.2.weight 0.4283472001552582\n",
      "mlp.2.bias 0.3185371160507202\n",
      "3Layer\n",
      "Epoch 015 | Loss 0.5248 | Val AUC 0.9070 | Val AUPR 0.6140\n",
      "3Layer\n",
      "mlp.0.weight 0.16600929200649261\n",
      "mlp.0.bias 0.12201526015996933\n",
      "mlp.2.weight 0.4421403110027313\n",
      "mlp.2.bias 0.30899733304977417\n",
      "3Layer\n",
      "Epoch 016 | Loss 0.5121 | Val AUC 0.9116 | Val AUPR 0.6733\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1645352691411972\n",
      "mlp.0.bias 0.1202709972858429\n",
      "mlp.2.weight 0.45363160967826843\n",
      "mlp.2.bias 0.29945194721221924\n",
      "3Layer\n",
      "Epoch 017 | Loss 0.4997 | Val AUC 0.9129 | Val AUPR 0.7001\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1617898941040039\n",
      "mlp.0.bias 0.11808329820632935\n",
      "mlp.2.weight 0.46283158659935\n",
      "mlp.2.bias 0.2901528775691986\n",
      "3Layer\n",
      "Epoch 018 | Loss 0.4880 | Val AUC 0.9147 | Val AUPR 0.7176\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15904873609542847\n",
      "mlp.0.bias 0.11540950834751129\n",
      "mlp.2.weight 0.47241201996803284\n",
      "mlp.2.bias 0.2800239324569702\n",
      "3Layer\n",
      "Epoch 019 | Loss 0.4752 | Val AUC 0.9150 | Val AUPR 0.7357\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1553269773721695\n",
      "mlp.0.bias 0.11293916404247284\n",
      "mlp.2.weight 0.4774041473865509\n",
      "mlp.2.bias 0.2706429958343506\n",
      "3Layer\n",
      "Epoch 020 | Loss 0.4641 | Val AUC 0.9159 | Val AUPR 0.7455\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15208058059215546\n",
      "mlp.0.bias 0.11002785712480545\n",
      "mlp.2.weight 0.48288825154304504\n",
      "mlp.2.bias 0.2604265511035919\n",
      "3Layer\n",
      "Epoch 021 | Loss 0.4518 | Val AUC 0.9157 | Val AUPR 0.7423\n",
      "3Layer\n",
      "mlp.0.weight 0.14826719462871552\n",
      "mlp.0.bias 0.10706165432929993\n",
      "mlp.2.weight 0.4860696494579315\n",
      "mlp.2.bias 0.2502959668636322\n",
      "3Layer\n",
      "Epoch 022 | Loss 0.4400 | Val AUC 0.9153 | Val AUPR 0.7269\n",
      "3Layer\n",
      "mlp.0.weight 0.14425106346607208\n",
      "mlp.0.bias 0.10405769944190979\n",
      "mlp.2.weight 0.4872532784938812\n",
      "mlp.2.bias 0.24029162526130676\n",
      "3Layer\n",
      "Epoch 023 | Loss 0.4288 | Val AUC 0.9148 | Val AUPR 0.6950\n",
      "3Layer\n",
      "mlp.0.weight 0.140009805560112\n",
      "mlp.0.bias 0.10088960826396942\n",
      "mlp.2.weight 0.48694097995758057\n",
      "mlp.2.bias 0.23012620210647583\n",
      "3Layer\n",
      "Epoch 024 | Loss 0.4175 | Val AUC 0.9136 | Val AUPR 0.6511\n",
      "3Layer\n",
      "mlp.0.weight 0.13572703301906586\n",
      "mlp.0.bias 0.09759966284036636\n",
      "mlp.2.weight 0.48489952087402344\n",
      "mlp.2.bias 0.21973317861557007\n",
      "3Layer\n",
      "Epoch 025 | Loss 0.4062 | Val AUC 0.9108 | Val AUPR 0.5929\n",
      "3Layer\n",
      "mlp.0.weight 0.13148891925811768\n",
      "mlp.0.bias 0.09447083622217178\n",
      "mlp.2.weight 0.4802689552307129\n",
      "mlp.2.bias 0.20932668447494507\n",
      "3Layer\n",
      "Epoch 026 | Loss 0.3954 | Val AUC 0.9120 | Val AUPR 0.5762\n",
      "3Layer\n",
      "mlp.0.weight 0.12781357765197754\n",
      "mlp.0.bias 0.09170489758253098\n",
      "mlp.2.weight 0.4743606746196747\n",
      "mlp.2.bias 0.1989535242319107\n",
      "3Layer\n",
      "Epoch 027 | Loss 0.3847 | Val AUC 0.9119 | Val AUPR 0.5652\n",
      "3Layer\n",
      "mlp.0.weight 0.12281736731529236\n",
      "mlp.0.bias 0.0880068838596344\n",
      "mlp.2.weight 0.4662167429924011\n",
      "mlp.2.bias 0.18836621940135956\n",
      "3Layer\n",
      "Epoch 028 | Loss 0.3742 | Val AUC 0.9117 | Val AUPR 0.5561\n",
      "3Layer\n",
      "mlp.0.weight 0.117674820125103\n",
      "mlp.0.bias 0.08434980362653732\n",
      "mlp.2.weight 0.4565763771533966\n",
      "mlp.2.bias 0.17831459641456604\n",
      "3Layer\n",
      "Epoch 029 | Loss 0.3645 | Val AUC 0.9121 | Val AUPR 0.5514\n",
      "3Layer\n",
      "mlp.0.weight 0.11226244270801544\n",
      "mlp.0.bias 0.08034670352935791\n",
      "mlp.2.weight 0.4453691840171814\n",
      "mlp.2.bias 0.167880117893219\n",
      "3Layer\n",
      "Epoch 030 | Loss 0.3547 | Val AUC 0.9124 | Val AUPR 0.5478\n",
      "3Layer\n",
      "mlp.0.weight 0.10681550204753876\n",
      "mlp.0.bias 0.07649485021829605\n",
      "mlp.2.weight 0.43240615725517273\n",
      "mlp.2.bias 0.15799522399902344\n",
      "3Layer\n",
      "Epoch 031 | Loss 0.3458 | Val AUC 0.9127 | Val AUPR 0.5391\n",
      "3Layer\n",
      "mlp.0.weight 0.10126796364784241\n",
      "mlp.0.bias 0.07229480892419815\n",
      "mlp.2.weight 0.41802942752838135\n",
      "mlp.2.bias 0.1476246565580368\n",
      "3Layer\n",
      "Epoch 032 | Loss 0.3365 | Val AUC 0.9138 | Val AUPR 0.5350\n",
      "3Layer\n",
      "mlp.0.weight 0.09577372670173645\n",
      "mlp.0.bias 0.06835538893938065\n",
      "mlp.2.weight 0.4025360643863678\n",
      "mlp.2.bias 0.13801662623882294\n",
      "3Layer\n",
      "Epoch 033 | Loss 0.3285 | Val AUC 0.9143 | Val AUPR 0.5310\n",
      "3Layer\n",
      "mlp.0.weight 0.09023405611515045\n",
      "mlp.0.bias 0.06444091349840164\n",
      "mlp.2.weight 0.38609620928764343\n",
      "mlp.2.bias 0.12867730855941772\n",
      "3Layer\n",
      "Epoch 034 | Loss 0.3208 | Val AUC 0.9138 | Val AUPR 0.5248\n",
      "3Layer\n",
      "mlp.0.weight 0.08467452973127365\n",
      "mlp.0.bias 0.06032704934477806\n",
      "mlp.2.weight 0.36829814314842224\n",
      "mlp.2.bias 0.11915600299835205\n",
      "3Layer\n",
      "Epoch 035 | Loss 0.3133 | Val AUC 0.9137 | Val AUPR 0.5205\n",
      "3Layer\n",
      "mlp.0.weight 0.07936522364616394\n",
      "mlp.0.bias 0.056502096354961395\n",
      "mlp.2.weight 0.3507569432258606\n",
      "mlp.2.bias 0.1104133129119873\n",
      "3Layer\n",
      "Epoch 036 | Loss 0.3065 | Val AUC 0.9134 | Val AUPR 0.5230\n",
      "3Layer\n",
      "mlp.0.weight 0.07389393448829651\n",
      "mlp.0.bias 0.052657559514045715\n",
      "mlp.2.weight 0.3315107822418213\n",
      "mlp.2.bias 0.10182789713144302\n",
      "3Layer\n",
      "Epoch 037 | Loss 0.3005 | Val AUC 0.9128 | Val AUPR 0.5244\n",
      "3Layer\n",
      "mlp.0.weight 0.06878956407308578\n",
      "mlp.0.bias 0.048961080610752106\n",
      "mlp.2.weight 0.31295645236968994\n",
      "mlp.2.bias 0.09371507167816162\n",
      "3Layer\n",
      "Epoch 038 | Loss 0.2947 | Val AUC 0.9124 | Val AUPR 0.5293\n",
      "3Layer\n",
      "mlp.0.weight 0.06357315927743912\n",
      "mlp.0.bias 0.04520761966705322\n",
      "mlp.2.weight 0.2931073307991028\n",
      "mlp.2.bias 0.0856705754995346\n",
      "3Layer\n",
      "Epoch 039 | Loss 0.2894 | Val AUC 0.9125 | Val AUPR 0.5312\n",
      "3Layer\n",
      "mlp.0.weight 0.05867719277739525\n",
      "mlp.0.bias 0.041656672954559326\n",
      "mlp.2.weight 0.27411168813705444\n",
      "mlp.2.bias 0.0781775489449501\n",
      "3Layer\n",
      "Epoch 040 | Loss 0.2845 | Val AUC 0.9129 | Val AUPR 0.5377\n",
      "3Layer\n",
      "mlp.0.weight 0.05379999801516533\n",
      "mlp.0.bias 0.03812501206994057\n",
      "mlp.2.weight 0.2544536888599396\n",
      "mlp.2.bias 0.07087712734937668\n",
      "3Layer\n",
      "Epoch 041 | Loss 0.2801 | Val AUC 0.9128 | Val AUPR 0.5377\n",
      "3Layer\n",
      "mlp.0.weight 0.04905680567026138\n",
      "mlp.0.bias 0.03477318584918976\n",
      "mlp.2.weight 0.234506756067276\n",
      "mlp.2.bias 0.06405693292617798\n",
      "3Layer\n",
      "Epoch 042 | Loss 0.2764 | Val AUC 0.9131 | Val AUPR 0.5366\n",
      "3Layer\n",
      "mlp.0.weight 0.04478271305561066\n",
      "mlp.0.bias 0.03175210580229759\n",
      "mlp.2.weight 0.2163219004869461\n",
      "mlp.2.bias 0.05797655135393143\n",
      "3Layer\n",
      "Epoch 043 | Loss 0.2731 | Val AUC 0.9130 | Val AUPR 0.5417\n",
      "3Layer\n",
      "mlp.0.weight 0.0403701514005661\n",
      "mlp.0.bias 0.028504174202680588\n",
      "mlp.2.weight 0.1969148963689804\n",
      "mlp.2.bias 0.051603902131319046\n",
      "3Layer\n",
      "Epoch 044 | Loss 0.2697 | Val AUC 0.9128 | Val AUPR 0.5444\n",
      "3Layer\n",
      "mlp.0.weight 0.0363880917429924\n",
      "mlp.0.bias 0.02572009712457657\n",
      "mlp.2.weight 0.17920717597007751\n",
      "mlp.2.bias 0.046182986348867416\n",
      "3Layer\n",
      "Epoch 045 | Loss 0.2673 | Val AUC 0.9131 | Val AUPR 0.5550\n",
      "3Layer\n",
      "mlp.0.weight 0.032569609582424164\n",
      "mlp.0.bias 0.023006221279501915\n",
      "mlp.2.weight 0.161801278591156\n",
      "mlp.2.bias 0.04098585993051529\n",
      "3Layer\n",
      "Epoch 046 | Loss 0.2651 | Val AUC 0.9132 | Val AUPR 0.5767\n",
      "3Layer\n",
      "mlp.0.weight 0.02892911247909069\n",
      "mlp.0.bias 0.02032294310629368\n",
      "mlp.2.weight 0.14472393691539764\n",
      "mlp.2.bias 0.03593367710709572\n",
      "3Layer\n",
      "Epoch 047 | Loss 0.2629 | Val AUC 0.9133 | Val AUPR 0.5931\n",
      "3Layer\n",
      "mlp.0.weight 0.025658300146460533\n",
      "mlp.0.bias 0.017997240647673607\n",
      "mlp.2.weight 0.1292894035577774\n",
      "mlp.2.bias 0.031593456864356995\n",
      "3Layer\n",
      "Epoch 048 | Loss 0.2613 | Val AUC 0.9129 | Val AUPR 0.6185\n",
      "3Layer\n",
      "mlp.0.weight 0.022447869181632996\n",
      "mlp.0.bias 0.015621921978890896\n",
      "mlp.2.weight 0.11371148377656937\n",
      "mlp.2.bias 0.02723657339811325\n",
      "3Layer\n",
      "Epoch 049 | Loss 0.2597 | Val AUC 0.9116 | Val AUPR 0.6320\n",
      "3Layer\n",
      "mlp.0.weight 0.01948588155210018\n",
      "mlp.0.bias 0.0134507417678833\n",
      "mlp.2.weight 0.09929817169904709\n",
      "mlp.2.bias 0.023299334570765495\n",
      "3Layer\n",
      "Epoch 050 | Loss 0.2583 | Val AUC 0.9105 | Val AUPR 0.6416\n",
      "3Layer\n",
      "SEED 43 | Test AUC 0.9060 | Test AUPR 0.6337\n",
      "\n",
      "==============================\n",
      "Running experiment with SEED = 44\n",
      "==============================\n",
      "3Layer\n",
      "mlp.0.weight 0.19453245401382446\n",
      "mlp.0.bias 0.17009924352169037\n",
      "mlp.2.weight 0.15448501706123352\n",
      "mlp.2.bias 0.4360887110233307\n",
      "3Layer\n",
      "Epoch 001 | Loss 0.7056 | Val AUC 0.8660 | Val AUPR 0.4448\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.17255432903766632\n",
      "mlp.0.bias 0.14854806661605835\n",
      "mlp.2.weight 0.1512434482574463\n",
      "mlp.2.bias 0.4204929769039154\n",
      "3Layer\n",
      "Epoch 002 | Loss 0.6785 | Val AUC 0.8512 | Val AUPR 0.3625\n",
      "3Layer\n",
      "mlp.0.weight 0.16093431413173676\n",
      "mlp.0.bias 0.13762806355953217\n",
      "mlp.2.weight 0.17565231025218964\n",
      "mlp.2.bias 0.4077182412147522\n",
      "3Layer\n",
      "Epoch 003 | Loss 0.6571 | Val AUC 0.8203 | Val AUPR 0.2743\n",
      "3Layer\n",
      "mlp.0.weight 0.16598719358444214\n",
      "mlp.0.bias 0.13735802471637726\n",
      "mlp.2.weight 0.2060098797082901\n",
      "mlp.2.bias 0.39673328399658203\n",
      "3Layer\n",
      "Epoch 004 | Loss 0.6395 | Val AUC 0.7088 | Val AUPR 0.1737\n",
      "3Layer\n",
      "mlp.0.weight 0.17250250279903412\n",
      "mlp.0.bias 0.13975845277309418\n",
      "mlp.2.weight 0.23406726121902466\n",
      "mlp.2.bias 0.3863027095794678\n",
      "3Layer\n",
      "Epoch 005 | Loss 0.6230 | Val AUC 0.6753 | Val AUPR 0.1657\n",
      "3Layer\n",
      "mlp.0.weight 0.18007183074951172\n",
      "mlp.0.bias 0.1444724053144455\n",
      "mlp.2.weight 0.25615978240966797\n",
      "mlp.2.bias 0.37648314237594604\n",
      "3Layer\n",
      "Epoch 006 | Loss 0.6080 | Val AUC 0.6720 | Val AUPR 0.1666\n",
      "3Layer\n",
      "mlp.0.weight 0.18774597346782684\n",
      "mlp.0.bias 0.1470719277858734\n",
      "mlp.2.weight 0.2791488766670227\n",
      "mlp.2.bias 0.36579546332359314\n",
      "3Layer\n",
      "Epoch 007 | Loss 0.5917 | Val AUC 0.6986 | Val AUPR 0.1866\n",
      "3Layer\n",
      "mlp.0.weight 0.1880628764629364\n",
      "mlp.0.bias 0.1461494117975235\n",
      "mlp.2.weight 0.2989184558391571\n",
      "mlp.2.bias 0.3560033440589905\n",
      "3Layer\n",
      "Epoch 008 | Loss 0.5771 | Val AUC 0.7215 | Val AUPR 0.1926\n",
      "3Layer\n",
      "mlp.0.weight 0.18932472169399261\n",
      "mlp.0.bias 0.14579175412654877\n",
      "mlp.2.weight 0.31595271825790405\n",
      "mlp.2.bias 0.3461295962333679\n",
      "3Layer\n",
      "Epoch 009 | Loss 0.5631 | Val AUC 0.7726 | Val AUPR 0.2247\n",
      "3Layer\n",
      "mlp.0.weight 0.19011110067367554\n",
      "mlp.0.bias 0.1447260081768036\n",
      "mlp.2.weight 0.3336471915245056\n",
      "mlp.2.bias 0.33611422777175903\n",
      "3Layer\n",
      "Epoch 010 | Loss 0.5487 | Val AUC 0.8229 | Val AUPR 0.2795\n",
      "3Layer\n",
      "mlp.0.weight 0.18969471752643585\n",
      "mlp.0.bias 0.1426941156387329\n",
      "mlp.2.weight 0.3493637144565582\n",
      "mlp.2.bias 0.32482674717903137\n",
      "3Layer\n",
      "Epoch 011 | Loss 0.5332 | Val AUC 0.8505 | Val AUPR 0.3262\n",
      "3Layer\n",
      "mlp.0.weight 0.18700549006462097\n",
      "mlp.0.bias 0.14009080827236176\n",
      "mlp.2.weight 0.36165833473205566\n",
      "mlp.2.bias 0.3149890601634979\n",
      "3Layer\n",
      "Epoch 012 | Loss 0.5199 | Val AUC 0.8770 | Val AUPR 0.4101\n",
      "3Layer\n",
      "mlp.0.weight 0.18329086899757385\n",
      "mlp.0.bias 0.13674059510231018\n",
      "mlp.2.weight 0.3757486045360565\n",
      "mlp.2.bias 0.30382901430130005\n",
      "3Layer\n",
      "Epoch 013 | Loss 0.5054 | Val AUC 0.8995 | Val AUPR 0.5284\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.18009191751480103\n",
      "mlp.0.bias 0.13325710594654083\n",
      "mlp.2.weight 0.3881853222846985\n",
      "mlp.2.bias 0.2926812767982483\n",
      "3Layer\n",
      "Epoch 014 | Loss 0.4911 | Val AUC 0.9084 | Val AUPR 0.5690\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.17624907195568085\n",
      "mlp.0.bias 0.12969264388084412\n",
      "mlp.2.weight 0.39806029200553894\n",
      "mlp.2.bias 0.2815825939178467\n",
      "3Layer\n",
      "Epoch 015 | Loss 0.4772 | Val AUC 0.9120 | Val AUPR 0.6039\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1715838462114334\n",
      "mlp.0.bias 0.1260606348514557\n",
      "mlp.2.weight 0.40665093064308167\n",
      "mlp.2.bias 0.27053773403167725\n",
      "3Layer\n",
      "Epoch 016 | Loss 0.4638 | Val AUC 0.9141 | Val AUPR 0.6235\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.16681523621082306\n",
      "mlp.0.bias 0.12224356085062027\n",
      "mlp.2.weight 0.4127366840839386\n",
      "mlp.2.bias 0.25930678844451904\n",
      "3Layer\n",
      "Epoch 017 | Loss 0.4506 | Val AUC 0.9144 | Val AUPR 0.6261\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1617322862148285\n",
      "mlp.0.bias 0.11811219155788422\n",
      "mlp.2.weight 0.41835612058639526\n",
      "mlp.2.bias 0.24763385951519012\n",
      "3Layer\n",
      "Epoch 018 | Loss 0.4371 | Val AUC 0.9142 | Val AUPR 0.6274\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15658657252788544\n",
      "mlp.0.bias 0.11389767378568649\n",
      "mlp.2.weight 0.42138803005218506\n",
      "mlp.2.bias 0.2360212802886963\n",
      "3Layer\n",
      "Epoch 019 | Loss 0.4239 | Val AUC 0.9143 | Val AUPR 0.6226\n",
      "3Layer\n",
      "mlp.0.weight 0.15106669068336487\n",
      "mlp.0.bias 0.10953231900930405\n",
      "mlp.2.weight 0.42223361134529114\n",
      "mlp.2.bias 0.22433650493621826\n",
      "3Layer\n",
      "Epoch 020 | Loss 0.4112 | Val AUC 0.9155 | Val AUPR 0.6243\n",
      "3Layer\n",
      "mlp.0.weight 0.14509177207946777\n",
      "mlp.0.bias 0.1051100492477417\n",
      "mlp.2.weight 0.42123112082481384\n",
      "mlp.2.bias 0.21278005838394165\n",
      "3Layer\n",
      "Epoch 021 | Loss 0.3988 | Val AUC 0.9163 | Val AUPR 0.6246\n",
      "3Layer\n",
      "mlp.0.weight 0.13894818723201752\n",
      "mlp.0.bias 0.10033570230007172\n",
      "mlp.2.weight 0.41791611909866333\n",
      "mlp.2.bias 0.20076417922973633\n",
      "3Layer\n",
      "Epoch 022 | Loss 0.3865 | Val AUC 0.9171 | Val AUPR 0.6239\n",
      "3Layer\n",
      "mlp.0.weight 0.1327981948852539\n",
      "mlp.0.bias 0.09579817950725555\n",
      "mlp.2.weight 0.41250288486480713\n",
      "mlp.2.bias 0.18947601318359375\n",
      "3Layer\n",
      "Epoch 023 | Loss 0.3752 | Val AUC 0.9179 | Val AUPR 0.6232\n",
      "3Layer\n",
      "mlp.0.weight 0.12647292017936707\n",
      "mlp.0.bias 0.09110933542251587\n",
      "mlp.2.weight 0.405075341463089\n",
      "mlp.2.bias 0.17813783884048462\n",
      "3Layer\n",
      "Epoch 024 | Loss 0.3643 | Val AUC 0.9185 | Val AUPR 0.6173\n",
      "3Layer\n",
      "mlp.0.weight 0.1200575903058052\n",
      "mlp.0.bias 0.08649548143148422\n",
      "mlp.2.weight 0.3956439197063446\n",
      "mlp.2.bias 0.16719399392604828\n",
      "3Layer\n",
      "Epoch 025 | Loss 0.3542 | Val AUC 0.9188 | Val AUPR 0.6116\n",
      "3Layer\n",
      "mlp.0.weight 0.11355806887149811\n",
      "mlp.0.bias 0.08156383037567139\n",
      "mlp.2.weight 0.3846149742603302\n",
      "mlp.2.bias 0.15588495135307312\n",
      "3Layer\n",
      "Epoch 026 | Loss 0.3438 | Val AUC 0.9196 | Val AUPR 0.6063\n",
      "3Layer\n",
      "mlp.0.weight 0.10702452063560486\n",
      "mlp.0.bias 0.07702353596687317\n",
      "mlp.2.weight 0.3724726736545563\n",
      "mlp.2.bias 0.14556695520877838\n",
      "3Layer\n",
      "Epoch 027 | Loss 0.3350 | Val AUC 0.9195 | Val AUPR 0.5989\n",
      "3Layer\n",
      "mlp.0.weight 0.10043463110923767\n",
      "mlp.0.bias 0.07184199243783951\n",
      "mlp.2.weight 0.35804226994514465\n",
      "mlp.2.bias 0.13428013026714325\n",
      "3Layer\n",
      "Epoch 028 | Loss 0.3252 | Val AUC 0.9188 | Val AUPR 0.5921\n",
      "3Layer\n",
      "mlp.0.weight 0.09393653273582458\n",
      "mlp.0.bias 0.06719283014535904\n",
      "mlp.2.weight 0.3428665101528168\n",
      "mlp.2.bias 0.1242281123995781\n",
      "3Layer\n",
      "Epoch 029 | Loss 0.3171 | Val AUC 0.9168 | Val AUPR 0.5764\n",
      "3Layer\n",
      "mlp.0.weight 0.08739519864320755\n",
      "mlp.0.bias 0.06250002980232239\n",
      "mlp.2.weight 0.326135516166687\n",
      "mlp.2.bias 0.11431899666786194\n",
      "3Layer\n",
      "Epoch 030 | Loss 0.3096 | Val AUC 0.9154 | Val AUPR 0.5704\n",
      "3Layer\n",
      "mlp.0.weight 0.08089329302310944\n",
      "mlp.0.bias 0.057784583419561386\n",
      "mlp.2.weight 0.3081552982330322\n",
      "mlp.2.bias 0.10458692908287048\n",
      "3Layer\n",
      "Epoch 031 | Loss 0.3025 | Val AUC 0.9129 | Val AUPR 0.5724\n",
      "3Layer\n",
      "mlp.0.weight 0.07475096732378006\n",
      "mlp.0.bias 0.05326062813401222\n",
      "mlp.2.weight 0.2902754843235016\n",
      "mlp.2.bias 0.09540996700525284\n",
      "3Layer\n",
      "Epoch 032 | Loss 0.2959 | Val AUC 0.9110 | Val AUPR 0.5661\n",
      "3Layer\n",
      "mlp.0.weight 0.06859354674816132\n",
      "mlp.0.bias 0.04897455498576164\n",
      "mlp.2.weight 0.27122199535369873\n",
      "mlp.2.bias 0.08685249835252762\n",
      "3Layer\n",
      "Epoch 033 | Loss 0.2904 | Val AUC 0.9100 | Val AUPR 0.5590\n",
      "3Layer\n",
      "mlp.0.weight 0.06274048984050751\n",
      "mlp.0.bias 0.04467982053756714\n",
      "mlp.2.weight 0.2525906562805176\n",
      "mlp.2.bias 0.07846180349588394\n",
      "3Layer\n",
      "Epoch 034 | Loss 0.2848 | Val AUC 0.9089 | Val AUPR 0.5525\n",
      "3Layer\n",
      "mlp.0.weight 0.056873153895139694\n",
      "mlp.0.bias 0.04040403664112091\n",
      "mlp.2.weight 0.2326689511537552\n",
      "mlp.2.bias 0.07027886807918549\n",
      "3Layer\n",
      "Epoch 035 | Loss 0.2799 | Val AUC 0.9091 | Val AUPR 0.5561\n",
      "3Layer\n",
      "mlp.0.weight 0.05160212889313698\n",
      "mlp.0.bias 0.03672175854444504\n",
      "mlp.2.weight 0.2142648994922638\n",
      "mlp.2.bias 0.06328526884317398\n",
      "3Layer\n",
      "Epoch 036 | Loss 0.2761 | Val AUC 0.9094 | Val AUPR 0.5580\n",
      "3Layer\n",
      "mlp.0.weight 0.04623334854841232\n",
      "mlp.0.bias 0.03283308073878288\n",
      "mlp.2.weight 0.19475309550762177\n",
      "mlp.2.bias 0.05607924982905388\n",
      "3Layer\n",
      "Epoch 037 | Loss 0.2722 | Val AUC 0.9099 | Val AUPR 0.5601\n",
      "3Layer\n",
      "mlp.0.weight 0.04117673635482788\n",
      "mlp.0.bias 0.02913917787373066\n",
      "mlp.2.weight 0.17567481100559235\n",
      "mlp.2.bias 0.04934221878647804\n",
      "3Layer\n",
      "Epoch 038 | Loss 0.2689 | Val AUC 0.9119 | Val AUPR 0.5692\n",
      "3Layer\n",
      "mlp.0.weight 0.036548513919115067\n",
      "mlp.0.bias 0.02583640068769455\n",
      "mlp.2.weight 0.1577800065279007\n",
      "mlp.2.bias 0.043388038873672485\n",
      "3Layer\n",
      "Epoch 039 | Loss 0.2661 | Val AUC 0.9133 | Val AUPR 0.5883\n",
      "3Layer\n",
      "mlp.0.weight 0.03202010318636894\n",
      "mlp.0.bias 0.022592883557081223\n",
      "mlp.2.weight 0.1397930085659027\n",
      "mlp.2.bias 0.03764062374830246\n",
      "3Layer\n",
      "Epoch 040 | Loss 0.2638 | Val AUC 0.9146 | Val AUPR 0.6053\n",
      "3Layer\n",
      "mlp.0.weight 0.02781008370220661\n",
      "mlp.0.bias 0.019597360864281654\n",
      "mlp.2.weight 0.12252478301525116\n",
      "mlp.2.bias 0.032403022050857544\n",
      "3Layer\n",
      "Epoch 041 | Loss 0.2619 | Val AUC 0.9162 | Val AUPR 0.6302\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.023903410881757736\n",
      "mlp.0.bias 0.016775134950876236\n",
      "mlp.2.weight 0.10640618950128555\n",
      "mlp.2.bias 0.02753700688481331\n",
      "3Layer\n",
      "Epoch 042 | Loss 0.2602 | Val AUC 0.9166 | Val AUPR 0.6459\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.020257985219359398\n",
      "mlp.0.bias 0.014130310155451298\n",
      "mlp.2.weight 0.0908733606338501\n",
      "mlp.2.bias 0.02303711697459221\n",
      "3Layer\n",
      "Epoch 043 | Loss 0.2588 | Val AUC 0.9171 | Val AUPR 0.6557\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.01678413711488247\n",
      "mlp.0.bias 0.011645598337054253\n",
      "mlp.2.weight 0.0757102519273758\n",
      "mlp.2.bias 0.01886381395161152\n",
      "3Layer\n",
      "Epoch 044 | Loss 0.2578 | Val AUC 0.9180 | Val AUPR 0.6610\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.013740556314587593\n",
      "mlp.0.bias 0.009434686042368412\n",
      "mlp.2.weight 0.062170520424842834\n",
      "mlp.2.bias 0.01518986839801073\n",
      "3Layer\n",
      "Epoch 045 | Loss 0.2569 | Val AUC 0.9186 | Val AUPR 0.6669\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.010883383452892303\n",
      "mlp.0.bias 0.00738315237686038\n",
      "mlp.2.weight 0.049322374165058136\n",
      "mlp.2.bias 0.011819400824606419\n",
      "3Layer\n",
      "Epoch 046 | Loss 0.2563 | Val AUC 0.9191 | Val AUPR 0.6699\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.008265774697065353\n",
      "mlp.0.bias 0.005460639484226704\n",
      "mlp.2.weight 0.037355899810791016\n",
      "mlp.2.bias 0.008695454336702824\n",
      "3Layer\n",
      "Epoch 047 | Loss 0.2558 | Val AUC 0.9194 | Val AUPR 0.6709\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.006215508561581373\n",
      "mlp.0.bias 0.0037780781276524067\n",
      "mlp.2.weight 0.0270445104688406\n",
      "mlp.2.bias 0.005986629985272884\n",
      "3Layer\n",
      "Epoch 048 | Loss 0.2552 | Val AUC 0.9188 | Val AUPR 0.6711\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.004391904454678297\n",
      "mlp.0.bias 0.002159219468012452\n",
      "mlp.2.weight 0.016461074352264404\n",
      "mlp.2.bias 0.0034059309400618076\n",
      "3Layer\n",
      "Epoch 049 | Loss 0.2550 | Val AUC 0.9181 | Val AUPR 0.6695\n",
      "3Layer\n",
      "mlp.0.weight 0.003162442473694682\n",
      "mlp.0.bias 0.0006653790478594601\n",
      "mlp.2.weight 0.0071068559773266315\n",
      "mlp.2.bias 0.001045198179781437\n",
      "3Layer\n",
      "Epoch 050 | Loss 0.2547 | Val AUC 0.9170 | Val AUPR 0.6703\n",
      "3Layer\n",
      "SEED 44 | Test AUC 0.8832 | Test AUPR 0.5553\n",
      "\n",
      "==============================\n",
      "Running experiment with SEED = 45\n",
      "==============================\n",
      "3Layer\n",
      "mlp.0.weight 0.18201084434986115\n",
      "mlp.0.bias 0.15376344323158264\n",
      "mlp.2.weight 0.18425701558589935\n",
      "mlp.2.bias 0.4179671108722687\n",
      "3Layer\n",
      "Epoch 001 | Loss 0.6748 | Val AUC 0.5290 | Val AUPR 0.1125\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.17354579269886017\n",
      "mlp.0.bias 0.14469246566295624\n",
      "mlp.2.weight 0.18890196084976196\n",
      "mlp.2.bias 0.4026183784008026\n",
      "3Layer\n",
      "Epoch 002 | Loss 0.6491 | Val AUC 0.7776 | Val AUPR 0.2547\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1742514669895172\n",
      "mlp.0.bias 0.14567455649375916\n",
      "mlp.2.weight 0.2077319324016571\n",
      "mlp.2.bias 0.389385461807251\n",
      "3Layer\n",
      "Epoch 003 | Loss 0.6277 | Val AUC 0.8458 | Val AUPR 0.3490\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1768023520708084\n",
      "mlp.0.bias 0.1439003050327301\n",
      "mlp.2.weight 0.2324855923652649\n",
      "mlp.2.bias 0.377377450466156\n",
      "3Layer\n",
      "Epoch 004 | Loss 0.6089 | Val AUC 0.8730 | Val AUPR 0.4211\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.18244139850139618\n",
      "mlp.0.bias 0.14640654623508453\n",
      "mlp.2.weight 0.2553747892379761\n",
      "mlp.2.bias 0.36625462770462036\n",
      "3Layer\n",
      "Epoch 005 | Loss 0.5920 | Val AUC 0.8838 | Val AUPR 0.4708\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.18566520512104034\n",
      "mlp.0.bias 0.14820504188537598\n",
      "mlp.2.weight 0.27701058983802795\n",
      "mlp.2.bias 0.3553410470485687\n",
      "3Layer\n",
      "Epoch 006 | Loss 0.5759 | Val AUC 0.9036 | Val AUPR 0.5927\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.19487668573856354\n",
      "mlp.0.bias 0.15176884829998016\n",
      "mlp.2.weight 0.2980329990386963\n",
      "mlp.2.bias 0.3437595069408417\n",
      "3Layer\n",
      "Epoch 007 | Loss 0.5592 | Val AUC 0.9057 | Val AUPR 0.5989\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.19501543045043945\n",
      "mlp.0.bias 0.1514607071876526\n",
      "mlp.2.weight 0.3126566410064697\n",
      "mlp.2.bias 0.3336523175239563\n",
      "3Layer\n",
      "Epoch 008 | Loss 0.5451 | Val AUC 0.9059 | Val AUPR 0.5859\n",
      "3Layer\n",
      "mlp.0.weight 0.19491824507713318\n",
      "mlp.0.bias 0.1487497240304947\n",
      "mlp.2.weight 0.32918521761894226\n",
      "mlp.2.bias 0.32115086913108826\n",
      "3Layer\n",
      "Epoch 009 | Loss 0.5280 | Val AUC 0.9055 | Val AUPR 0.5855\n",
      "3Layer\n",
      "mlp.0.weight 0.1928846687078476\n",
      "mlp.0.bias 0.1455278843641281\n",
      "mlp.2.weight 0.34375715255737305\n",
      "mlp.2.bias 0.3092620074748993\n",
      "3Layer\n",
      "Epoch 010 | Loss 0.5121 | Val AUC 0.9036 | Val AUPR 0.5917\n",
      "3Layer\n",
      "mlp.0.weight 0.18950000405311584\n",
      "mlp.0.bias 0.14227867126464844\n",
      "mlp.2.weight 0.3546481132507324\n",
      "mlp.2.bias 0.29804739356040955\n",
      "3Layer\n",
      "Epoch 011 | Loss 0.4973 | Val AUC 0.8973 | Val AUPR 0.5395\n",
      "3Layer\n",
      "mlp.0.weight 0.18695057928562164\n",
      "mlp.0.bias 0.13955186307430267\n",
      "mlp.2.weight 0.36470794677734375\n",
      "mlp.2.bias 0.2861161231994629\n",
      "3Layer\n",
      "Epoch 012 | Loss 0.4825 | Val AUC 0.8958 | Val AUPR 0.5356\n",
      "3Layer\n",
      "mlp.0.weight 0.18374960124492645\n",
      "mlp.0.bias 0.1358613222837448\n",
      "mlp.2.weight 0.3740895390510559\n",
      "mlp.2.bias 0.27368223667144775\n",
      "3Layer\n",
      "Epoch 013 | Loss 0.4672 | Val AUC 0.8946 | Val AUPR 0.5259\n",
      "3Layer\n",
      "mlp.0.weight 0.17867137491703033\n",
      "mlp.0.bias 0.13169541954994202\n",
      "mlp.2.weight 0.38011008501052856\n",
      "mlp.2.bias 0.26177406311035156\n",
      "3Layer\n",
      "Epoch 014 | Loss 0.4531 | Val AUC 0.8919 | Val AUPR 0.5075\n",
      "3Layer\n",
      "mlp.0.weight 0.1732654869556427\n",
      "mlp.0.bias 0.12714862823486328\n",
      "mlp.2.weight 0.38424989581108093\n",
      "mlp.2.bias 0.24953442811965942\n",
      "3Layer\n",
      "Epoch 015 | Loss 0.4389 | Val AUC 0.8885 | Val AUPR 0.4888\n",
      "3Layer\n",
      "mlp.0.weight 0.16731147468090057\n",
      "mlp.0.bias 0.12230126559734344\n",
      "mlp.2.weight 0.3872736692428589\n",
      "mlp.2.bias 0.23724034428596497\n",
      "3Layer\n",
      "Epoch 016 | Loss 0.4251 | Val AUC 0.8872 | Val AUPR 0.4883\n",
      "3Layer\n",
      "mlp.0.weight 0.1610083431005478\n",
      "mlp.0.bias 0.11734915524721146\n",
      "mlp.2.weight 0.3883953392505646\n",
      "mlp.2.bias 0.2250489443540573\n",
      "3Layer\n",
      "Epoch 017 | Loss 0.4116 | Val AUC 0.8855 | Val AUPR 0.4812\n",
      "3Layer\n",
      "mlp.0.weight 0.15440818667411804\n",
      "mlp.0.bias 0.11217623949050903\n",
      "mlp.2.weight 0.38656964898109436\n",
      "mlp.2.bias 0.21269509196281433\n",
      "3Layer\n",
      "Epoch 018 | Loss 0.3985 | Val AUC 0.8842 | Val AUPR 0.4856\n",
      "3Layer\n",
      "mlp.0.weight 0.14776703715324402\n",
      "mlp.0.bias 0.10693254321813583\n",
      "mlp.2.weight 0.38327616453170776\n",
      "mlp.2.bias 0.20046401023864746\n",
      "3Layer\n",
      "Epoch 019 | Loss 0.3859 | Val AUC 0.8846 | Val AUPR 0.4940\n",
      "3Layer\n",
      "mlp.0.weight 0.14081181585788727\n",
      "mlp.0.bias 0.1018509790301323\n",
      "mlp.2.weight 0.37818557024002075\n",
      "mlp.2.bias 0.1887875497341156\n",
      "3Layer\n",
      "Epoch 020 | Loss 0.3743 | Val AUC 0.8871 | Val AUPR 0.5120\n",
      "3Layer\n",
      "mlp.0.weight 0.1336705982685089\n",
      "mlp.0.bias 0.09652530401945114\n",
      "mlp.2.weight 0.3709551990032196\n",
      "mlp.2.bias 0.17690911889076233\n",
      "3Layer\n",
      "Epoch 021 | Loss 0.3628 | Val AUC 0.8882 | Val AUPR 0.5099\n",
      "3Layer\n",
      "mlp.0.weight 0.12625955045223236\n",
      "mlp.0.bias 0.090936578810215\n",
      "mlp.2.weight 0.3617483377456665\n",
      "mlp.2.bias 0.16480708122253418\n",
      "3Layer\n",
      "Epoch 022 | Loss 0.3516 | Val AUC 0.8904 | Val AUPR 0.5000\n",
      "3Layer\n",
      "mlp.0.weight 0.11880402266979218\n",
      "mlp.0.bias 0.08541958034038544\n",
      "mlp.2.weight 0.3509868383407593\n",
      "mlp.2.bias 0.1530941277742386\n",
      "3Layer\n",
      "Epoch 023 | Loss 0.3412 | Val AUC 0.8922 | Val AUPR 0.4991\n",
      "3Layer\n",
      "mlp.0.weight 0.11144959926605225\n",
      "mlp.0.bias 0.08014362305402756\n",
      "mlp.2.weight 0.3393154442310333\n",
      "mlp.2.bias 0.14206205308437347\n",
      "3Layer\n",
      "Epoch 024 | Loss 0.3315 | Val AUC 0.8949 | Val AUPR 0.5141\n",
      "3Layer\n",
      "mlp.0.weight 0.10404371470212936\n",
      "mlp.0.bias 0.07464022189378738\n",
      "mlp.2.weight 0.3248949646949768\n",
      "mlp.2.bias 0.1308707296848297\n",
      "3Layer\n",
      "Epoch 025 | Loss 0.3223 | Val AUC 0.8979 | Val AUPR 0.5291\n",
      "3Layer\n",
      "mlp.0.weight 0.0966569036245346\n",
      "mlp.0.bias 0.06920799612998962\n",
      "mlp.2.weight 0.30964457988739014\n",
      "mlp.2.bias 0.12004609405994415\n",
      "3Layer\n",
      "Epoch 026 | Loss 0.3137 | Val AUC 0.9000 | Val AUPR 0.5322\n",
      "3Layer\n",
      "mlp.0.weight 0.08944825083017349\n",
      "mlp.0.bias 0.06398741155862808\n",
      "mlp.2.weight 0.2935603857040405\n",
      "mlp.2.bias 0.10981948673725128\n",
      "3Layer\n",
      "Epoch 027 | Loss 0.3059 | Val AUC 0.9021 | Val AUPR 0.5492\n",
      "3Layer\n",
      "mlp.0.weight 0.08247014880180359\n",
      "mlp.0.bias 0.05885147303342819\n",
      "mlp.2.weight 0.2767261862754822\n",
      "mlp.2.bias 0.0999574363231659\n",
      "3Layer\n",
      "Epoch 028 | Loss 0.2986 | Val AUC 0.9046 | Val AUPR 0.5762\n",
      "3Layer\n",
      "mlp.0.weight 0.07542137056589127\n",
      "mlp.0.bias 0.05374133586883545\n",
      "mlp.2.weight 0.2583910822868347\n",
      "mlp.2.bias 0.09034999459981918\n",
      "3Layer\n",
      "Epoch 029 | Loss 0.2921 | Val AUC 0.9068 | Val AUPR 0.5986\n",
      "3Layer\n",
      "mlp.0.weight 0.06893924623727798\n",
      "mlp.0.bias 0.04908040538430214\n",
      "mlp.2.weight 0.24077731370925903\n",
      "mlp.2.bias 0.081693634390831\n",
      "3Layer\n",
      "Epoch 030 | Loss 0.2864 | Val AUC 0.9092 | Val AUPR 0.6051\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.062257055193185806\n",
      "mlp.0.bias 0.04436175897717476\n",
      "mlp.2.weight 0.2218315750360489\n",
      "mlp.2.bias 0.07312335819005966\n",
      "3Layer\n",
      "Epoch 031 | Loss 0.2813 | Val AUC 0.9110 | Val AUPR 0.6258\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.05614181607961655\n",
      "mlp.0.bias 0.039899371564388275\n",
      "mlp.2.weight 0.20332328975200653\n",
      "mlp.2.bias 0.06514739990234375\n",
      "3Layer\n",
      "Epoch 032 | Loss 0.2766 | Val AUC 0.9124 | Val AUPR 0.6277\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.050132568925619125\n",
      "mlp.0.bias 0.0354899987578392\n",
      "mlp.2.weight 0.18448692560195923\n",
      "mlp.2.bias 0.05741766095161438\n",
      "3Layer\n",
      "Epoch 033 | Loss 0.2723 | Val AUC 0.9142 | Val AUPR 0.6311\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.044537778943777084\n",
      "mlp.0.bias 0.03148406371474266\n",
      "mlp.2.weight 0.16635027527809143\n",
      "mlp.2.bias 0.05048613250255585\n",
      "3Layer\n",
      "Epoch 034 | Loss 0.2689 | Val AUC 0.9163 | Val AUPR 0.6423\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.0390995591878891\n",
      "mlp.0.bias 0.02753150276839733\n",
      "mlp.2.weight 0.1479511857032776\n",
      "mlp.2.bias 0.043771740049123764\n",
      "3Layer\n",
      "Epoch 035 | Loss 0.2658 | Val AUC 0.9175 | Val AUPR 0.6576\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.034156061708927155\n",
      "mlp.0.bias 0.024035615846514702\n",
      "mlp.2.weight 0.13092808425426483\n",
      "mlp.2.bias 0.03790096938610077\n",
      "3Layer\n",
      "Epoch 036 | Loss 0.2634 | Val AUC 0.9183 | Val AUPR 0.6679\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.029556220397353172\n",
      "mlp.0.bias 0.020717892795801163\n",
      "mlp.2.weight 0.11437437683343887\n",
      "mlp.2.bias 0.032413531094789505\n",
      "3Layer\n",
      "Epoch 037 | Loss 0.2614 | Val AUC 0.9184 | Val AUPR 0.6700\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.025181900709867477\n",
      "mlp.0.bias 0.01742253638803959\n",
      "mlp.2.weight 0.098411925137043\n",
      "mlp.2.bias 0.027054401114583015\n",
      "3Layer\n",
      "Epoch 038 | Loss 0.2591 | Val AUC 0.9193 | Val AUPR 0.6725\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.021027548238635063\n",
      "mlp.0.bias 0.014466222375631332\n",
      "mlp.2.weight 0.08291023224592209\n",
      "mlp.2.bias 0.02230450138449669\n",
      "3Layer\n",
      "Epoch 039 | Loss 0.2578 | Val AUC 0.9189 | Val AUPR 0.6758\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.01723378710448742\n",
      "mlp.0.bias 0.011800689622759819\n",
      "mlp.2.weight 0.06840222328901291\n",
      "mlp.2.bias 0.018072793260216713\n",
      "3Layer\n",
      "Epoch 040 | Loss 0.2570 | Val AUC 0.9182 | Val AUPR 0.6765\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.013933397829532623\n",
      "mlp.0.bias 0.009251498617231846\n",
      "mlp.2.weight 0.05512705817818642\n",
      "mlp.2.bias 0.014079381711781025\n",
      "3Layer\n",
      "Epoch 041 | Loss 0.2558 | Val AUC 0.9167 | Val AUPR 0.6748\n",
      "3Layer\n",
      "mlp.0.weight 0.010962731204926968\n",
      "mlp.0.bias 0.006909561809152365\n",
      "mlp.2.weight 0.04274037852883339\n",
      "mlp.2.bias 0.010453231632709503\n",
      "3Layer\n",
      "Epoch 042 | Loss 0.2549 | Val AUC 0.9160 | Val AUPR 0.6717\n",
      "3Layer\n",
      "mlp.0.weight 0.008737589232623577\n",
      "mlp.0.bias 0.004893001168966293\n",
      "mlp.2.weight 0.03188741207122803\n",
      "mlp.2.bias 0.007361728698015213\n",
      "3Layer\n",
      "Epoch 043 | Loss 0.2542 | Val AUC 0.9146 | Val AUPR 0.6695\n",
      "3Layer\n",
      "mlp.0.weight 0.006812982726842165\n",
      "mlp.0.bias 0.0030278272461146116\n",
      "mlp.2.weight 0.021516405045986176\n",
      "mlp.2.bias 0.004532264079898596\n",
      "3Layer\n",
      "Epoch 044 | Loss 0.2539 | Val AUC 0.9129 | Val AUPR 0.6645\n",
      "3Layer\n",
      "mlp.0.weight 0.004970787558704615\n",
      "mlp.0.bias 0.001334258820861578\n",
      "mlp.2.weight 0.012027665041387081\n",
      "mlp.2.bias 0.001987823750823736\n",
      "3Layer\n",
      "Epoch 045 | Loss 0.2536 | Val AUC 0.9121 | Val AUPR 0.6633\n",
      "3Layer\n",
      "mlp.0.weight 0.005145360250025988\n",
      "mlp.0.bias 6.288982694968581e-05\n",
      "mlp.2.weight 0.005221492610871792\n",
      "mlp.2.bias 9.329058229923248e-05\n",
      "3Layer\n",
      "Epoch 046 | Loss 0.2528 | Val AUC 0.9105 | Val AUPR 0.6622\n",
      "3Layer\n",
      "mlp.0.weight 0.005853299517184496\n",
      "mlp.0.bias 0.0013494775630533695\n",
      "mlp.2.weight 0.0023764611687511206\n",
      "mlp.2.bias 0.0019939930643886328\n",
      "3Layer\n",
      "Epoch 047 | Loss 0.2520 | Val AUC 0.9081 | Val AUPR 0.6565\n",
      "3Layer\n",
      "mlp.0.weight 0.005948960315436125\n",
      "mlp.0.bias 0.0023835173342376947\n",
      "mlp.2.weight 0.007731328718364239\n",
      "mlp.2.bias 0.003509379457682371\n",
      "3Layer\n",
      "Epoch 048 | Loss 0.2521 | Val AUC 0.9060 | Val AUPR 0.6492\n",
      "3Layer\n",
      "mlp.0.weight 0.007293612230569124\n",
      "mlp.0.bias 0.0032069494482129812\n",
      "mlp.2.weight 0.01079892460256815\n",
      "mlp.2.bias 0.00470668263733387\n",
      "3Layer\n",
      "Epoch 049 | Loss 0.2510 | Val AUC 0.9036 | Val AUPR 0.6457\n",
      "3Layer\n",
      "mlp.0.weight 0.007830953225493431\n",
      "mlp.0.bias 0.0037396063562482595\n",
      "mlp.2.weight 0.013008329086005688\n",
      "mlp.2.bias 0.005472749937325716\n",
      "3Layer\n",
      "Epoch 050 | Loss 0.2504 | Val AUC 0.9011 | Val AUPR 0.6414\n",
      "3Layer\n",
      "SEED 45 | Test AUC 0.9034 | Test AUPR 0.5739\n",
      "\n",
      "==============================\n",
      "Running experiment with SEED = 46\n",
      "==============================\n",
      "3Layer\n",
      "mlp.0.weight 0.1530977040529251\n",
      "mlp.0.bias 0.1302708387374878\n",
      "mlp.2.weight 0.1437157541513443\n",
      "mlp.2.bias 0.4522646367549896\n",
      "3Layer\n",
      "Epoch 001 | Loss 0.7344 | Val AUC 0.8218 | Val AUPR 0.2741\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1469295471906662\n",
      "mlp.0.bias 0.12427930533885956\n",
      "mlp.2.weight 0.16297762095928192\n",
      "mlp.2.bias 0.44035544991493225\n",
      "3Layer\n",
      "Epoch 002 | Loss 0.7128 | Val AUC 0.8624 | Val AUPR 0.3866\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.14561884105205536\n",
      "mlp.0.bias 0.12137400358915329\n",
      "mlp.2.weight 0.19459031522274017\n",
      "mlp.2.bias 0.42984434962272644\n",
      "3Layer\n",
      "Epoch 003 | Loss 0.6942 | Val AUC 0.8971 | Val AUPR 0.4589\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.14936724305152893\n",
      "mlp.0.bias 0.1223270520567894\n",
      "mlp.2.weight 0.22716867923736572\n",
      "mlp.2.bias 0.4208128750324249\n",
      "3Layer\n",
      "Epoch 004 | Loss 0.6787 | Val AUC 0.8962 | Val AUPR 0.4621\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15336522459983826\n",
      "mlp.0.bias 0.12418907880783081\n",
      "mlp.2.weight 0.2574894428253174\n",
      "mlp.2.bias 0.4123024344444275\n",
      "3Layer\n",
      "Epoch 005 | Loss 0.6645 | Val AUC 0.9053 | Val AUPR 0.5040\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.1582970768213272\n",
      "mlp.0.bias 0.124814972281456\n",
      "mlp.2.weight 0.2867836058139801\n",
      "mlp.2.bias 0.4041613042354584\n",
      "3Layer\n",
      "Epoch 006 | Loss 0.6512 | Val AUC 0.9013 | Val AUPR 0.5119\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.15966853499412537\n",
      "mlp.0.bias 0.12603868544101715\n",
      "mlp.2.weight 0.309291273355484\n",
      "mlp.2.bias 0.3968561291694641\n",
      "3Layer\n",
      "Epoch 007 | Loss 0.6395 | Val AUC 0.8949 | Val AUPR 0.4875\n",
      "3Layer\n",
      "mlp.0.weight 0.1661907136440277\n",
      "mlp.0.bias 0.12805216014385223\n",
      "mlp.2.weight 0.33475664258003235\n",
      "mlp.2.bias 0.3886016607284546\n",
      "3Layer\n",
      "Epoch 008 | Loss 0.6264 | Val AUC 0.8816 | Val AUPR 0.4252\n",
      "3Layer\n",
      "mlp.0.weight 0.17136019468307495\n",
      "mlp.0.bias 0.13095097243785858\n",
      "mlp.2.weight 0.35351815819740295\n",
      "mlp.2.bias 0.38065728545188904\n",
      "3Layer\n",
      "Epoch 009 | Loss 0.6140 | Val AUC 0.8823 | Val AUPR 0.4221\n",
      "3Layer\n",
      "mlp.0.weight 0.1736711859703064\n",
      "mlp.0.bias 0.13204322755336761\n",
      "mlp.2.weight 0.368881493806839\n",
      "mlp.2.bias 0.3732124865055084\n",
      "3Layer\n",
      "Epoch 010 | Loss 0.6029 | Val AUC 0.8793 | Val AUPR 0.4029\n",
      "3Layer\n",
      "mlp.0.weight 0.17632105946540833\n",
      "mlp.0.bias 0.1333809494972229\n",
      "mlp.2.weight 0.38572952151298523\n",
      "mlp.2.bias 0.36487093567848206\n",
      "3Layer\n",
      "Epoch 011 | Loss 0.5904 | Val AUC 0.8592 | Val AUPR 0.3193\n",
      "3Layer\n",
      "mlp.0.weight 0.17957377433776855\n",
      "mlp.0.bias 0.13382965326309204\n",
      "mlp.2.weight 0.40403223037719727\n",
      "mlp.2.bias 0.3555065989494324\n",
      "3Layer\n",
      "Epoch 012 | Loss 0.5767 | Val AUC 0.8383 | Val AUPR 0.2848\n",
      "3Layer\n",
      "mlp.0.weight 0.18010041117668152\n",
      "mlp.0.bias 0.1339603066444397\n",
      "mlp.2.weight 0.4199560582637787\n",
      "mlp.2.bias 0.3465125560760498\n",
      "3Layer\n",
      "Epoch 013 | Loss 0.5636 | Val AUC 0.8308 | Val AUPR 0.2797\n",
      "3Layer\n",
      "mlp.0.weight 0.18078382313251495\n",
      "mlp.0.bias 0.13368844985961914\n",
      "mlp.2.weight 0.4327757954597473\n",
      "mlp.2.bias 0.3372882604598999\n",
      "3Layer\n",
      "Epoch 014 | Loss 0.5506 | Val AUC 0.8269 | Val AUPR 0.2782\n",
      "3Layer\n",
      "mlp.0.weight 0.1795499324798584\n",
      "mlp.0.bias 0.13215138018131256\n",
      "mlp.2.weight 0.44723954796791077\n",
      "mlp.2.bias 0.3272874355316162\n",
      "3Layer\n",
      "Epoch 015 | Loss 0.5369 | Val AUC 0.8295 | Val AUPR 0.2880\n",
      "3Layer\n",
      "mlp.0.weight 0.17749421298503876\n",
      "mlp.0.bias 0.1300525963306427\n",
      "mlp.2.weight 0.459211528301239\n",
      "mlp.2.bias 0.31732234358787537\n",
      "3Layer\n",
      "Epoch 016 | Loss 0.5233 | Val AUC 0.8408 | Val AUPR 0.3242\n",
      "3Layer\n",
      "mlp.0.weight 0.1746399998664856\n",
      "mlp.0.bias 0.12751801311969757\n",
      "mlp.2.weight 0.47044822573661804\n",
      "mlp.2.bias 0.3071201741695404\n",
      "3Layer\n",
      "Epoch 017 | Loss 0.5099 | Val AUC 0.8534 | Val AUPR 0.3863\n",
      "3Layer\n",
      "mlp.0.weight 0.17103518545627594\n",
      "mlp.0.bias 0.12489628046751022\n",
      "mlp.2.weight 0.47920969128608704\n",
      "mlp.2.bias 0.297027051448822\n",
      "3Layer\n",
      "Epoch 018 | Loss 0.4968 | Val AUC 0.8597 | Val AUPR 0.4342\n",
      "3Layer\n",
      "mlp.0.weight 0.16766846179962158\n",
      "mlp.0.bias 0.12177858501672745\n",
      "mlp.2.weight 0.48831531405448914\n",
      "mlp.2.bias 0.2859710454940796\n",
      "3Layer\n",
      "Epoch 019 | Loss 0.4828 | Val AUC 0.8624 | Val AUPR 0.4532\n",
      "3Layer\n",
      "mlp.0.weight 0.16343344748020172\n",
      "mlp.0.bias 0.11873923242092133\n",
      "mlp.2.weight 0.4938724637031555\n",
      "mlp.2.bias 0.2753124535083771\n",
      "3Layer\n",
      "Epoch 020 | Loss 0.4699 | Val AUC 0.8674 | Val AUPR 0.4683\n",
      "3Layer\n",
      "mlp.0.weight 0.159361332654953\n",
      "mlp.0.bias 0.11541581153869629\n",
      "mlp.2.weight 0.4981611967086792\n",
      "mlp.2.bias 0.2641891539096832\n",
      "3Layer\n",
      "Epoch 021 | Loss 0.4565 | Val AUC 0.8721 | Val AUPR 0.4796\n",
      "3Layer\n",
      "mlp.0.weight 0.15477006137371063\n",
      "mlp.0.bias 0.11206356436014175\n",
      "mlp.2.weight 0.5007444620132446\n",
      "mlp.2.bias 0.25317224860191345\n",
      "3Layer\n",
      "Epoch 022 | Loss 0.4436 | Val AUC 0.8757 | Val AUPR 0.4895\n",
      "3Layer\n",
      "mlp.0.weight 0.15010717511177063\n",
      "mlp.0.bias 0.10830257087945938\n",
      "mlp.2.weight 0.5014892220497131\n",
      "mlp.2.bias 0.24152794480323792\n",
      "3Layer\n",
      "Epoch 023 | Loss 0.4302 | Val AUC 0.8782 | Val AUPR 0.4851\n",
      "3Layer\n",
      "mlp.0.weight 0.14513100683689117\n",
      "mlp.0.bias 0.1044403612613678\n",
      "mlp.2.weight 0.5003464221954346\n",
      "mlp.2.bias 0.22996895015239716\n",
      "3Layer\n",
      "Epoch 024 | Loss 0.4173 | Val AUC 0.8809 | Val AUPR 0.4904\n",
      "3Layer\n",
      "mlp.0.weight 0.13965575397014618\n",
      "mlp.0.bias 0.10058550536632538\n",
      "mlp.2.weight 0.49606016278266907\n",
      "mlp.2.bias 0.2186940312385559\n",
      "3Layer\n",
      "Epoch 025 | Loss 0.4053 | Val AUC 0.8837 | Val AUPR 0.4987\n",
      "3Layer\n",
      "mlp.0.weight 0.1341867297887802\n",
      "mlp.0.bias 0.09647902101278305\n",
      "mlp.2.weight 0.49023953080177307\n",
      "mlp.2.bias 0.20714038610458374\n",
      "3Layer\n",
      "Epoch 026 | Loss 0.3932 | Val AUC 0.8857 | Val AUPR 0.5038\n",
      "3Layer\n",
      "mlp.0.weight 0.12854062020778656\n",
      "mlp.0.bias 0.09232526272535324\n",
      "mlp.2.weight 0.4823462665081024\n",
      "mlp.2.bias 0.19575704634189606\n",
      "3Layer\n",
      "Epoch 027 | Loss 0.3816 | Val AUC 0.8883 | Val AUPR 0.5133\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.12264644354581833\n",
      "mlp.0.bias 0.08804518729448318\n",
      "mlp.2.weight 0.47226807475090027\n",
      "mlp.2.bias 0.18437853455543518\n",
      "3Layer\n",
      "Epoch 028 | Loss 0.3704 | Val AUC 0.8914 | Val AUPR 0.5277\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.11662155389785767\n",
      "mlp.0.bias 0.08354361355304718\n",
      "mlp.2.weight 0.4602544903755188\n",
      "mlp.2.bias 0.1728132665157318\n",
      "3Layer\n",
      "Epoch 029 | Loss 0.3594 | Val AUC 0.8951 | Val AUPR 0.5373\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.11071669310331345\n",
      "mlp.0.bias 0.07932879030704498\n",
      "mlp.2.weight 0.44683969020843506\n",
      "mlp.2.bias 0.1621112823486328\n",
      "3Layer\n",
      "Epoch 030 | Loss 0.3495 | Val AUC 0.8982 | Val AUPR 0.5577\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.10456987470388412\n",
      "mlp.0.bias 0.07473962008953094\n",
      "mlp.2.weight 0.43163585662841797\n",
      "mlp.2.bias 0.1509103924036026\n",
      "3Layer\n",
      "Epoch 031 | Loss 0.3394 | Val AUC 0.9018 | Val AUPR 0.5794\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.09837230294942856\n",
      "mlp.0.bias 0.07024551928043365\n",
      "mlp.2.weight 0.41459253430366516\n",
      "mlp.2.bias 0.1401677131652832\n",
      "3Layer\n",
      "Epoch 032 | Loss 0.3302 | Val AUC 0.9055 | Val AUPR 0.6113\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.09220513701438904\n",
      "mlp.0.bias 0.0658007264137268\n",
      "mlp.2.weight 0.3959791362285614\n",
      "mlp.2.bias 0.12977907061576843\n",
      "3Layer\n",
      "Epoch 033 | Loss 0.3217 | Val AUC 0.9077 | Val AUPR 0.6398\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.08618182688951492\n",
      "mlp.0.bias 0.06147442013025284\n",
      "mlp.2.weight 0.3772207200527191\n",
      "mlp.2.bias 0.1198684498667717\n",
      "3Layer\n",
      "Epoch 034 | Loss 0.3138 | Val AUC 0.9102 | Val AUPR 0.6596\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.08013281971216202\n",
      "mlp.0.bias 0.057099372148513794\n",
      "mlp.2.weight 0.35684406757354736\n",
      "mlp.2.bias 0.11009760200977325\n",
      "3Layer\n",
      "Epoch 035 | Loss 0.3063 | Val AUC 0.9127 | Val AUPR 0.6707\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.07422489672899246\n",
      "mlp.0.bias 0.05278468504548073\n",
      "mlp.2.weight 0.3360957205295563\n",
      "mlp.2.bias 0.10066953301429749\n",
      "3Layer\n",
      "Epoch 036 | Loss 0.2994 | Val AUC 0.9149 | Val AUPR 0.6776\n",
      "   → Saved best model\n",
      "3Layer\n",
      "mlp.0.weight 0.06840407848358154\n",
      "mlp.0.bias 0.04864732548594475\n",
      "mlp.2.weight 0.3146238327026367\n",
      "mlp.2.bias 0.09179267287254333\n",
      "3Layer\n",
      "Epoch 037 | Loss 0.2933 | Val AUC 0.9162 | Val AUPR 0.6685\n",
      "3Layer\n",
      "mlp.0.weight 0.0627892017364502\n",
      "mlp.0.bias 0.044605132192373276\n",
      "mlp.2.weight 0.29304179549217224\n",
      "mlp.2.bias 0.08329436182975769\n",
      "3Layer\n",
      "Epoch 038 | Loss 0.2876 | Val AUC 0.9167 | Val AUPR 0.6686\n",
      "3Layer\n",
      "mlp.0.weight 0.05733967199921608\n",
      "mlp.0.bias 0.040643978863954544\n",
      "mlp.2.weight 0.27132490277290344\n",
      "mlp.2.bias 0.07513435930013657\n",
      "3Layer\n",
      "Epoch 039 | Loss 0.2825 | Val AUC 0.9163 | Val AUPR 0.6619\n",
      "3Layer\n",
      "mlp.0.weight 0.05192139744758606\n",
      "mlp.0.bias 0.03676898404955864\n",
      "mlp.2.weight 0.24889357388019562\n",
      "mlp.2.bias 0.06730885803699493\n",
      "3Layer\n",
      "Epoch 040 | Loss 0.2780 | Val AUC 0.9161 | Val AUPR 0.6609\n",
      "3Layer\n",
      "mlp.0.weight 0.04702066257596016\n",
      "mlp.0.bias 0.033332500606775284\n",
      "mlp.2.weight 0.22812609374523163\n",
      "mlp.2.bias 0.060443613678216934\n",
      "3Layer\n",
      "Epoch 041 | Loss 0.2742 | Val AUC 0.9168 | Val AUPR 0.6564\n",
      "3Layer\n",
      "mlp.0.weight 0.042112767696380615\n",
      "mlp.0.bias 0.029773971065878868\n",
      "mlp.2.weight 0.20672720670700073\n",
      "mlp.2.bias 0.05350077897310257\n",
      "3Layer\n",
      "Epoch 042 | Loss 0.2706 | Val AUC 0.9180 | Val AUPR 0.6564\n",
      "3Layer\n",
      "mlp.0.weight 0.03761649876832962\n",
      "mlp.0.bias 0.026517905294895172\n",
      "mlp.2.weight 0.18651597201824188\n",
      "mlp.2.bias 0.04723435640335083\n",
      "3Layer\n",
      "Epoch 043 | Loss 0.2675 | Val AUC 0.9184 | Val AUPR 0.6522\n",
      "3Layer\n",
      "mlp.0.weight 0.03323594108223915\n",
      "mlp.0.bias 0.023406105116009712\n",
      "mlp.2.weight 0.16640064120292664\n",
      "mlp.2.bias 0.041343048214912415\n",
      "3Layer\n",
      "Epoch 044 | Loss 0.2650 | Val AUC 0.9186 | Val AUPR 0.6534\n",
      "3Layer\n",
      "mlp.0.weight 0.029098793864250183\n",
      "mlp.0.bias 0.02043205313384533\n",
      "mlp.2.weight 0.1469641923904419\n",
      "mlp.2.bias 0.03580166772007942\n",
      "3Layer\n",
      "Epoch 045 | Loss 0.2627 | Val AUC 0.9186 | Val AUPR 0.6548\n",
      "3Layer\n",
      "mlp.0.weight 0.0254617128521204\n",
      "mlp.0.bias 0.01777193322777748\n",
      "mlp.2.weight 0.12944015860557556\n",
      "mlp.2.bias 0.03090372309088707\n",
      "3Layer\n",
      "Epoch 046 | Loss 0.2608 | Val AUC 0.9189 | Val AUPR 0.6572\n",
      "3Layer\n",
      "mlp.0.weight 0.021947385743260384\n",
      "mlp.0.bias 0.01521885022521019\n",
      "mlp.2.weight 0.11245927214622498\n",
      "mlp.2.bias 0.026273122057318687\n",
      "3Layer\n",
      "Epoch 047 | Loss 0.2591 | Val AUC 0.9181 | Val AUPR 0.6545\n",
      "3Layer\n",
      "mlp.0.weight 0.018762603402137756\n",
      "mlp.0.bias 0.012841940857470036\n",
      "mlp.2.weight 0.09641733765602112\n",
      "mlp.2.bias 0.02201833203434944\n",
      "3Layer\n",
      "Epoch 048 | Loss 0.2577 | Val AUC 0.9170 | Val AUPR 0.6553\n",
      "3Layer\n",
      "mlp.0.weight 0.015644967555999756\n",
      "mlp.0.bias 0.01051431242376566\n",
      "mlp.2.weight 0.08053453266620636\n",
      "mlp.2.bias 0.01791139878332615\n",
      "3Layer\n",
      "Epoch 049 | Loss 0.2564 | Val AUC 0.9163 | Val AUPR 0.6546\n",
      "3Layer\n",
      "mlp.0.weight 0.012969429604709148\n",
      "mlp.0.bias 0.008576384745538235\n",
      "mlp.2.weight 0.0666436180472374\n",
      "mlp.2.bias 0.014521767385303974\n",
      "3Layer\n",
      "Epoch 050 | Loss 0.2558 | Val AUC 0.9145 | Val AUPR 0.6528\n",
      "3Layer\n",
      "SEED 46 | Test AUC 0.8938 | Test AUPR 0.5178\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Running experiment with SEED = {seed}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    # ---- model must be re-created AFTER seed ----\n",
    "    model = HeteroGraphSAGE(\n",
    "        in_channels=data[\"circRNA\"].x.size(1),\n",
    "        hidden_channels=64,\n",
    "        out_channels=64,\n",
    "        dropout=0.2\n",
    "    ).to(DEVICE)\n",
    "    predictor = LinkPredictor(dim=64).to(DEVICE)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(predictor.parameters()),\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_aupr = 0.0\n",
    "    best_val_loss = None\n",
    "\n",
    "\n",
    "    # -------- Training loop --------\n",
    "    for epoch in range(1, 51):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        emb = model(data.x_dict, data.edge_index_dict)\n",
    "        circ_emb, dis_emb = emb[\"circRNA\"], emb[\"disease\"]\n",
    "\n",
    "        logits = predictor(circ_emb[train_edges[0]],dis_emb[train_edges[1]])\n",
    "        loss = loss_fn(logits, train_labels)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        for name, p in predictor.named_parameters():\n",
    "            print(name, p.grad.norm().item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # -------- Validation --------\n",
    "        model.eval()\n",
    "        predictor.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = model(data.x_dict, data.edge_index_dict)\n",
    "            circ_emb, dis_emb = emb[\"circRNA\"], emb[\"disease\"]\n",
    "\n",
    "            val_logits = predictor(circ_emb[val_edges[0]],dis_emb[val_edges[1]])\n",
    "            val_scores = torch.sigmoid(val_logits).cpu().numpy()\n",
    "            val_true   = val_labels.cpu().numpy()\n",
    "\n",
    "            auc = roc_auc_score(val_true, val_scores)\n",
    "            aupr = average_precision_score(val_true, val_scores)\n",
    "        print(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"Loss {loss.item():.4f} | \"\n",
    "        f\"Val AUC {auc:.4f} | \"\n",
    "        f\"Val AUPR {aupr:.4f}\"\n",
    "        )\n",
    "\n",
    "        if aupr > best_val_aupr:\n",
    "            best_val_aupr = aupr\n",
    "            best_val_loss = loss.item()\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"predictor\": predictor.state_dict()\n",
    "                },\n",
    "                OUT_DIR / f\"sage_best_model_seed{seed}.pth\"\n",
    "            )\n",
    "\n",
    "            print(\"   → Saved best model\")\n",
    "\n",
    "    # -------- Test evaluation --------\n",
    "    ckpt = torch.load(\n",
    "        OUT_DIR / f\"sage_best_model_seed{seed}.pth\",\n",
    "        map_location=DEVICE\n",
    "    )\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    predictor.load_state_dict(ckpt[\"predictor\"])\n",
    "\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = model(data.x_dict, data.edge_index_dict)\n",
    "        circ_emb, dis_emb = emb[\"circRNA\"], emb[\"disease\"]\n",
    "\n",
    "        test_logits = predictor(\n",
    "            circ_emb[test_edges[0]],\n",
    "            dis_emb[test_edges[1]]\n",
    "        )\n",
    "        test_scores = torch.sigmoid(test_logits).cpu().numpy()\n",
    "\n",
    "        test_true   = test_labels.cpu().numpy()\n",
    "\n",
    "        test_auc  = roc_auc_score(test_true, test_scores)\n",
    "        test_aupr = average_precision_score(test_true, test_scores)\n",
    "\n",
    "    print(f\"SEED {seed} | Test AUC {test_auc:.4f} | Test AUPR {test_aupr:.4f}\")\n",
    "\n",
    "    results.append((seed, best_val_loss, test_auc, test_aupr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93cbe29-a60d-4204-9a26-f54d231d58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL RESULTS =====\n",
      "   seed  best_val_loss       auc      aupr\n",
      "0    42       0.364543  0.898877  0.587469\n",
      "1    43       0.464123  0.905987  0.633714\n",
      "2    44       0.255183  0.883161  0.555311\n",
      "3    45       0.256997  0.903421  0.573914\n",
      "4    46       0.299408  0.893817  0.517792\n",
      "\n",
      "Mean ± Std\n",
      "      best_val_loss       auc      aupr\n",
      "mean       0.328051  0.897053  0.573640\n",
      "std        0.088071  0.009044  0.042588\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"seed\", \"best_val_loss\", \"auc\", \"aupr\"]\n",
    ")\n",
    "\n",
    "print(\"\\n===== FINAL RESULTS =====\")\n",
    "print(results_df)\n",
    "print(\"\\nMean ± Std\")\n",
    "print(\n",
    "    results_df[[\"best_val_loss\", \"auc\", \"aupr\"]]\n",
    "    .agg([\"mean\", \"std\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458e3ea-9047-4ffe-8c8c-aac963c6233b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
